{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBR1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNuZPKicryr2oCNeps8Nxi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomlfx/ApiaryFund/blob/master/XGBR1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBR17XyPDFl",
        "outputId": "7e450d86-87ca-442a-c2a0-b88778e9b55a"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (3.3.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.1.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L33tTbkVyHeD"
      },
      "source": [
        "#designed for Jupyter/kaggle/colab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import matplotlib for plotting \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#import normalization\n",
        "from sklearn import preprocessing\n",
        "import xgboost as xg\n",
        "from sklearn.ensemble import RandomForestRegressor as rf\n",
        "#import auto hyperparameter tuning\n",
        "from flaml import AutoML"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv2oYmBSAHBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff2876c-83cc-412f-b7e8-8bf3a9b162ca"
      },
      "source": [
        " #MT4 csv \n",
        "df1=pd.read_csv('EURUSD1440.csv', names=['d','t','eu_o','eu_h','eu_l','eu_c','eu_v'])\n",
        "df1 = df1.tail(2000)\n",
        "df2=pd.read_csv('GBPUSD1440.csv', names=['d','t','gu_o','gu_h','gu_l','gu_c','gu_v'])\n",
        "df2 = df2.tail(2000)\n",
        "\n",
        "df3=pd.read_csv('USDCAD1440.csv', names=['d','t','uc_o','uc_h','uc_l','uc_c','uc_v'])\n",
        "df3 = df3.tail(2000)\n",
        "\n",
        "df4=pd.read_csv('USDCHF1440.csv', names=['d','t','uf_o','uf_h','uf_l','uf_c','uf_v'])\n",
        "df4 = df4.tail(2000)\n",
        "\n",
        "df5=pd.read_csv('USDJPY1440.csv', names=['d','t','uj_o','uj_h','uj_l','uj_c','uj_v'])\n",
        "df5 = df5.tail(2000)\n",
        "\n",
        "df6=pd.read_csv('USDSEK1440.csv', names=['d','t','us_o','us_h','us_l','us_c','us_v'])\n",
        "df6 = df6.tail(2000)\n",
        "\n",
        "#using merge\n",
        "df_m_1 = df1.merge(df2, on='d')\n",
        "df_m_2 = df_m_1.merge(df3, on='d')\n",
        "df_m_3 = df_m_2.merge(df4, on='d')\n",
        "df_m_4 = df_m_3.merge(df5, on='d')\n",
        "df_m_5 = df_m_4.merge(df6, on='d')\n",
        "df_m_5 = df_m_5.drop(columns='t_x')\n",
        "df_m_5 = df_m_5.drop(columns='t_y')\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(df_m_5) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               d     eu_o     eu_h     eu_l     eu_c    eu_v     gu_o  \\\n",
            "0     2014.03.25  1.38381  1.38470  1.37490  1.38250   77931  1.64960   \n",
            "1     2014.03.26  1.38249  1.38263  1.37762  1.37830   65921  1.65249   \n",
            "2     2014.03.27  1.37834  1.37967  1.37283  1.37437   73853  1.65791   \n",
            "3     2014.03.28  1.37436  1.37729  1.37047  1.37513   62308  1.66098   \n",
            "4     2014.03.31  1.37531  1.38085  1.37215  1.37735   71330  1.66550   \n",
            "...          ...      ...      ...      ...      ...     ...      ...   \n",
            "1993  2021.12.02  1.13191  1.13475  1.12952  1.13013   97454  1.32719   \n",
            "1994  2021.12.03  1.13005  1.13333  1.12665  1.13088  113218  1.32970   \n",
            "1995  2021.12.06  1.12997  1.13109  1.12664  1.12848   79067  1.32360   \n",
            "1996  2021.12.07  1.12821  1.12982  1.12273  1.12681   78783  1.32613   \n",
            "1997  2021.12.08  1.12650  1.12724  1.12627  1.12704     630  1.32382   \n",
            "\n",
            "         gu_h     gu_l     gu_c   gu_v     uc_o     uc_h     uc_l     uc_c  \\\n",
            "0     1.65492  1.64807  1.65287  62865  1.11885  1.12102  1.11550  1.11667   \n",
            "1     1.65969  1.65092  1.65807  61534  1.11646  1.11698  1.10806  1.11004   \n",
            "2     1.66468  1.65549  1.66091  65339  1.11002  1.11064  1.10138  1.10300   \n",
            "3     1.66510  1.65970  1.66423  43700  1.10300  1.10777  1.10008  1.10601   \n",
            "4     1.66838  1.66114  1.66628  50419  1.10623  1.10670  1.10022  1.10493   \n",
            "...       ...      ...      ...    ...      ...      ...      ...      ...   \n",
            "1993  1.33331  1.32656  1.32998  37311  1.28133  1.28374  1.27780  1.28048   \n",
            "1994  1.33094  1.32081  1.32300  38625  1.28018  1.28536  1.27434  1.28488   \n",
            "1995  1.32858  1.32220  1.32623  34613  1.28291  1.28422  1.27530  1.27560   \n",
            "1996  1.32890  1.32085  1.32419  33858  1.27557  1.27669  1.26347  1.26383   \n",
            "1997  1.32449  1.32333  1.32438    628  1.26393  1.26464  1.26370  1.26442   \n",
            "\n",
            "       uc_v     uf_o     uf_h     uf_l     uf_c   uf_v     uj_o     uj_h  \\\n",
            "0     31599  0.88049  0.88787  0.88011  0.88264  52546  102.224  102.487   \n",
            "1     37543  0.88217  0.88698  0.88217  0.88501  54998  102.239  102.470   \n",
            "2     42492  0.88501  0.88737  0.88405  0.88655  52222  102.041  102.433   \n",
            "3     34317  0.88647  0.88989  0.88485  0.88680  43890  102.178  102.978   \n",
            "4     38962  0.88545  0.88896  0.88244  0.88450  54490  102.948  103.440   \n",
            "...     ...      ...      ...      ...      ...    ...      ...      ...   \n",
            "1993  38280  0.91906  0.92213  0.91780  0.92023  28813  112.725  113.328   \n",
            "1994  38257  0.91998  0.92173  0.91655  0.91786  30287  113.003  113.610   \n",
            "1995  32905  0.91716  0.92688  0.91656  0.92551  25926  112.863  113.552   \n",
            "1996  30074  0.92478  0.92748  0.92306  0.92486  24666  113.451  113.776   \n",
            "1997    687  0.92480  0.92510  0.92368  0.92467    298  113.518  113.590   \n",
            "\n",
            "         uj_l     uj_c   uj_v     us_o     us_h     us_l     us_c   us_v  \n",
            "0     102.095  102.250  67655  6.39631  6.43821  6.39088  6.39991  54431  \n",
            "1     101.873  102.047  59783  6.39991  6.46701  6.39686  6.45866  52403  \n",
            "2     101.721  102.180  52354  6.45857  6.49001  6.45290  6.47607  58932  \n",
            "3     102.034  102.826  41508  6.47607  6.50488  6.46876  6.50011  47490  \n",
            "4     102.795  103.223  44773  6.49601  6.51493  6.46431  6.46637  61136  \n",
            "...       ...      ...    ...      ...      ...      ...      ...    ...  \n",
            "1993  112.698  113.185  58505  9.06588  9.09029  9.02448  9.04490  38791  \n",
            "1994  112.556  112.828  57050  9.03786  9.17935  9.03547  9.14200  38831  \n",
            "1995  112.846  113.484  51711  9.15248  9.16979  8.98850  9.08968  33157  \n",
            "1996  113.397  113.568  40041  9.07722  9.13943  9.04948  9.09611  34249  \n",
            "1997  113.486  113.534    792  9.10286  9.11585  9.09562  9.09670    449  \n",
            "\n",
            "[1998 rows x 31 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "wv_Xq-NlXzui",
        "outputId": "7971b355-a765-4f3a-e3a0-8801cce2624f"
      },
      "source": [
        "df_m_5.tail()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>eu_o</th>\n",
              "      <th>eu_h</th>\n",
              "      <th>eu_l</th>\n",
              "      <th>eu_c</th>\n",
              "      <th>eu_v</th>\n",
              "      <th>gu_o</th>\n",
              "      <th>gu_h</th>\n",
              "      <th>gu_l</th>\n",
              "      <th>gu_c</th>\n",
              "      <th>gu_v</th>\n",
              "      <th>uc_o</th>\n",
              "      <th>uc_h</th>\n",
              "      <th>uc_l</th>\n",
              "      <th>uc_c</th>\n",
              "      <th>uc_v</th>\n",
              "      <th>uf_o</th>\n",
              "      <th>uf_h</th>\n",
              "      <th>uf_l</th>\n",
              "      <th>uf_c</th>\n",
              "      <th>uf_v</th>\n",
              "      <th>uj_o</th>\n",
              "      <th>uj_h</th>\n",
              "      <th>uj_l</th>\n",
              "      <th>uj_c</th>\n",
              "      <th>uj_v</th>\n",
              "      <th>us_o</th>\n",
              "      <th>us_h</th>\n",
              "      <th>us_l</th>\n",
              "      <th>us_c</th>\n",
              "      <th>us_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>2021.12.02</td>\n",
              "      <td>1.13191</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>97454</td>\n",
              "      <td>1.32719</td>\n",
              "      <td>1.33331</td>\n",
              "      <td>1.32656</td>\n",
              "      <td>1.32998</td>\n",
              "      <td>37311</td>\n",
              "      <td>1.28133</td>\n",
              "      <td>1.28374</td>\n",
              "      <td>1.27780</td>\n",
              "      <td>1.28048</td>\n",
              "      <td>38280</td>\n",
              "      <td>0.91906</td>\n",
              "      <td>0.92213</td>\n",
              "      <td>0.91780</td>\n",
              "      <td>0.92023</td>\n",
              "      <td>28813</td>\n",
              "      <td>112.725</td>\n",
              "      <td>113.328</td>\n",
              "      <td>112.698</td>\n",
              "      <td>113.185</td>\n",
              "      <td>58505</td>\n",
              "      <td>9.06588</td>\n",
              "      <td>9.09029</td>\n",
              "      <td>9.02448</td>\n",
              "      <td>9.04490</td>\n",
              "      <td>38791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>2021.12.03</td>\n",
              "      <td>1.13005</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>113218</td>\n",
              "      <td>1.32970</td>\n",
              "      <td>1.33094</td>\n",
              "      <td>1.32081</td>\n",
              "      <td>1.32300</td>\n",
              "      <td>38625</td>\n",
              "      <td>1.28018</td>\n",
              "      <td>1.28536</td>\n",
              "      <td>1.27434</td>\n",
              "      <td>1.28488</td>\n",
              "      <td>38257</td>\n",
              "      <td>0.91998</td>\n",
              "      <td>0.92173</td>\n",
              "      <td>0.91655</td>\n",
              "      <td>0.91786</td>\n",
              "      <td>30287</td>\n",
              "      <td>113.003</td>\n",
              "      <td>113.610</td>\n",
              "      <td>112.556</td>\n",
              "      <td>112.828</td>\n",
              "      <td>57050</td>\n",
              "      <td>9.03786</td>\n",
              "      <td>9.17935</td>\n",
              "      <td>9.03547</td>\n",
              "      <td>9.14200</td>\n",
              "      <td>38831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>2021.12.06</td>\n",
              "      <td>1.12997</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>79067</td>\n",
              "      <td>1.32360</td>\n",
              "      <td>1.32858</td>\n",
              "      <td>1.32220</td>\n",
              "      <td>1.32623</td>\n",
              "      <td>34613</td>\n",
              "      <td>1.28291</td>\n",
              "      <td>1.28422</td>\n",
              "      <td>1.27530</td>\n",
              "      <td>1.27560</td>\n",
              "      <td>32905</td>\n",
              "      <td>0.91716</td>\n",
              "      <td>0.92688</td>\n",
              "      <td>0.91656</td>\n",
              "      <td>0.92551</td>\n",
              "      <td>25926</td>\n",
              "      <td>112.863</td>\n",
              "      <td>113.552</td>\n",
              "      <td>112.846</td>\n",
              "      <td>113.484</td>\n",
              "      <td>51711</td>\n",
              "      <td>9.15248</td>\n",
              "      <td>9.16979</td>\n",
              "      <td>8.98850</td>\n",
              "      <td>9.08968</td>\n",
              "      <td>33157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>2021.12.07</td>\n",
              "      <td>1.12821</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>78783</td>\n",
              "      <td>1.32613</td>\n",
              "      <td>1.32890</td>\n",
              "      <td>1.32085</td>\n",
              "      <td>1.32419</td>\n",
              "      <td>33858</td>\n",
              "      <td>1.27557</td>\n",
              "      <td>1.27669</td>\n",
              "      <td>1.26347</td>\n",
              "      <td>1.26383</td>\n",
              "      <td>30074</td>\n",
              "      <td>0.92478</td>\n",
              "      <td>0.92748</td>\n",
              "      <td>0.92306</td>\n",
              "      <td>0.92486</td>\n",
              "      <td>24666</td>\n",
              "      <td>113.451</td>\n",
              "      <td>113.776</td>\n",
              "      <td>113.397</td>\n",
              "      <td>113.568</td>\n",
              "      <td>40041</td>\n",
              "      <td>9.07722</td>\n",
              "      <td>9.13943</td>\n",
              "      <td>9.04948</td>\n",
              "      <td>9.09611</td>\n",
              "      <td>34249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>2021.12.08</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.12724</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.12704</td>\n",
              "      <td>630</td>\n",
              "      <td>1.32382</td>\n",
              "      <td>1.32449</td>\n",
              "      <td>1.32333</td>\n",
              "      <td>1.32438</td>\n",
              "      <td>628</td>\n",
              "      <td>1.26393</td>\n",
              "      <td>1.26464</td>\n",
              "      <td>1.26370</td>\n",
              "      <td>1.26442</td>\n",
              "      <td>687</td>\n",
              "      <td>0.92480</td>\n",
              "      <td>0.92510</td>\n",
              "      <td>0.92368</td>\n",
              "      <td>0.92467</td>\n",
              "      <td>298</td>\n",
              "      <td>113.518</td>\n",
              "      <td>113.590</td>\n",
              "      <td>113.486</td>\n",
              "      <td>113.534</td>\n",
              "      <td>792</td>\n",
              "      <td>9.10286</td>\n",
              "      <td>9.11585</td>\n",
              "      <td>9.09562</td>\n",
              "      <td>9.09670</td>\n",
              "      <td>449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               d     eu_o     eu_h     eu_l     eu_c    eu_v     gu_o  \\\n",
              "1993  2021.12.02  1.13191  1.13475  1.12952  1.13013   97454  1.32719   \n",
              "1994  2021.12.03  1.13005  1.13333  1.12665  1.13088  113218  1.32970   \n",
              "1995  2021.12.06  1.12997  1.13109  1.12664  1.12848   79067  1.32360   \n",
              "1996  2021.12.07  1.12821  1.12982  1.12273  1.12681   78783  1.32613   \n",
              "1997  2021.12.08  1.12650  1.12724  1.12627  1.12704     630  1.32382   \n",
              "\n",
              "         gu_h     gu_l     gu_c   gu_v     uc_o     uc_h     uc_l     uc_c  \\\n",
              "1993  1.33331  1.32656  1.32998  37311  1.28133  1.28374  1.27780  1.28048   \n",
              "1994  1.33094  1.32081  1.32300  38625  1.28018  1.28536  1.27434  1.28488   \n",
              "1995  1.32858  1.32220  1.32623  34613  1.28291  1.28422  1.27530  1.27560   \n",
              "1996  1.32890  1.32085  1.32419  33858  1.27557  1.27669  1.26347  1.26383   \n",
              "1997  1.32449  1.32333  1.32438    628  1.26393  1.26464  1.26370  1.26442   \n",
              "\n",
              "       uc_v     uf_o     uf_h     uf_l     uf_c   uf_v     uj_o     uj_h  \\\n",
              "1993  38280  0.91906  0.92213  0.91780  0.92023  28813  112.725  113.328   \n",
              "1994  38257  0.91998  0.92173  0.91655  0.91786  30287  113.003  113.610   \n",
              "1995  32905  0.91716  0.92688  0.91656  0.92551  25926  112.863  113.552   \n",
              "1996  30074  0.92478  0.92748  0.92306  0.92486  24666  113.451  113.776   \n",
              "1997    687  0.92480  0.92510  0.92368  0.92467    298  113.518  113.590   \n",
              "\n",
              "         uj_l     uj_c   uj_v     us_o     us_h     us_l     us_c   us_v  \n",
              "1993  112.698  113.185  58505  9.06588  9.09029  9.02448  9.04490  38791  \n",
              "1994  112.556  112.828  57050  9.03786  9.17935  9.03547  9.14200  38831  \n",
              "1995  112.846  113.484  51711  9.15248  9.16979  8.98850  9.08968  33157  \n",
              "1996  113.397  113.568  40041  9.07722  9.13943  9.04948  9.09611  34249  \n",
              "1997  113.486  113.534    792  9.10286  9.11585  9.09562  9.09670    449  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXIM5S0O1UHY"
      },
      "source": [
        "df_m_5.insert(1,'index',df_m_5.index)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT4vPMgBZrg8"
      },
      "source": [
        "#new column: high vs low\n",
        "df_m_5['eu_h_or_l'] = ((df_m_5.eu_h - df_m_5.eu_o) > (df_m_5.eu_o - df_m_5.eu_l)) \n",
        "df_m_5.eu_h_or_l = df_m_5.eu_h_or_l.replace({True:1,False:0})\n",
        "\n",
        "#new column: close vs yesterday\n",
        "df_m_5['eu_c_vs_c'] = (df_m_5.eu_c > df_m_5.eu_o) \n",
        "df_m_5.eu_c_vs_c = df_m_5.eu_c_vs_c.replace({True:1,False:0})\n",
        "\n",
        "#new column: shift tomorrow to today\n",
        "df_m_5['eu_High_next_day'] = df_m_5['eu_h'].shift(-1)\n",
        "df_m_5['eu_Low_next_day'] = df_m_5['eu_l'].shift(-1)\n",
        "df_m_5['eu_Close_next_day'] = df_m_5['eu_c'].shift(-1)\n",
        "df_m_5 = df_m_5.dropna()\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "sbaNPw8ctli1",
        "outputId": "8cef25f7-6736-4939-c463-74b15b35c294"
      },
      "source": [
        "df_m_5.tail()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>index</th>\n",
              "      <th>eu_o</th>\n",
              "      <th>eu_h</th>\n",
              "      <th>eu_l</th>\n",
              "      <th>eu_c</th>\n",
              "      <th>eu_v</th>\n",
              "      <th>gu_o</th>\n",
              "      <th>gu_h</th>\n",
              "      <th>gu_l</th>\n",
              "      <th>gu_c</th>\n",
              "      <th>gu_v</th>\n",
              "      <th>uc_o</th>\n",
              "      <th>uc_h</th>\n",
              "      <th>uc_l</th>\n",
              "      <th>uc_c</th>\n",
              "      <th>uc_v</th>\n",
              "      <th>uf_o</th>\n",
              "      <th>uf_h</th>\n",
              "      <th>uf_l</th>\n",
              "      <th>uf_c</th>\n",
              "      <th>uf_v</th>\n",
              "      <th>uj_o</th>\n",
              "      <th>uj_h</th>\n",
              "      <th>uj_l</th>\n",
              "      <th>uj_c</th>\n",
              "      <th>uj_v</th>\n",
              "      <th>us_o</th>\n",
              "      <th>us_h</th>\n",
              "      <th>us_l</th>\n",
              "      <th>us_c</th>\n",
              "      <th>us_v</th>\n",
              "      <th>eu_h_or_l</th>\n",
              "      <th>eu_c_vs_c</th>\n",
              "      <th>eu_High_next_day</th>\n",
              "      <th>eu_Low_next_day</th>\n",
              "      <th>eu_Close_next_day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1992</th>\n",
              "      <td>2021.12.01</td>\n",
              "      <td>1992</td>\n",
              "      <td>1.13329</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>122540</td>\n",
              "      <td>1.32967</td>\n",
              "      <td>1.33515</td>\n",
              "      <td>1.32612</td>\n",
              "      <td>1.32716</td>\n",
              "      <td>42174</td>\n",
              "      <td>1.27766</td>\n",
              "      <td>1.28293</td>\n",
              "      <td>1.27127</td>\n",
              "      <td>1.28225</td>\n",
              "      <td>39839</td>\n",
              "      <td>0.91832</td>\n",
              "      <td>0.92176</td>\n",
              "      <td>0.91690</td>\n",
              "      <td>0.92043</td>\n",
              "      <td>33483</td>\n",
              "      <td>113.087</td>\n",
              "      <td>113.625</td>\n",
              "      <td>112.667</td>\n",
              "      <td>112.767</td>\n",
              "      <td>62416</td>\n",
              "      <td>9.00866</td>\n",
              "      <td>9.08965</td>\n",
              "      <td>8.99263</td>\n",
              "      <td>9.07443</td>\n",
              "      <td>41090</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>2021.12.02</td>\n",
              "      <td>1993</td>\n",
              "      <td>1.13191</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>97454</td>\n",
              "      <td>1.32719</td>\n",
              "      <td>1.33331</td>\n",
              "      <td>1.32656</td>\n",
              "      <td>1.32998</td>\n",
              "      <td>37311</td>\n",
              "      <td>1.28133</td>\n",
              "      <td>1.28374</td>\n",
              "      <td>1.27780</td>\n",
              "      <td>1.28048</td>\n",
              "      <td>38280</td>\n",
              "      <td>0.91906</td>\n",
              "      <td>0.92213</td>\n",
              "      <td>0.91780</td>\n",
              "      <td>0.92023</td>\n",
              "      <td>28813</td>\n",
              "      <td>112.725</td>\n",
              "      <td>113.328</td>\n",
              "      <td>112.698</td>\n",
              "      <td>113.185</td>\n",
              "      <td>58505</td>\n",
              "      <td>9.06588</td>\n",
              "      <td>9.09029</td>\n",
              "      <td>9.02448</td>\n",
              "      <td>9.04490</td>\n",
              "      <td>38791</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994</th>\n",
              "      <td>2021.12.03</td>\n",
              "      <td>1994</td>\n",
              "      <td>1.13005</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>113218</td>\n",
              "      <td>1.32970</td>\n",
              "      <td>1.33094</td>\n",
              "      <td>1.32081</td>\n",
              "      <td>1.32300</td>\n",
              "      <td>38625</td>\n",
              "      <td>1.28018</td>\n",
              "      <td>1.28536</td>\n",
              "      <td>1.27434</td>\n",
              "      <td>1.28488</td>\n",
              "      <td>38257</td>\n",
              "      <td>0.91998</td>\n",
              "      <td>0.92173</td>\n",
              "      <td>0.91655</td>\n",
              "      <td>0.91786</td>\n",
              "      <td>30287</td>\n",
              "      <td>113.003</td>\n",
              "      <td>113.610</td>\n",
              "      <td>112.556</td>\n",
              "      <td>112.828</td>\n",
              "      <td>57050</td>\n",
              "      <td>9.03786</td>\n",
              "      <td>9.17935</td>\n",
              "      <td>9.03547</td>\n",
              "      <td>9.14200</td>\n",
              "      <td>38831</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>2021.12.06</td>\n",
              "      <td>1995</td>\n",
              "      <td>1.12997</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>79067</td>\n",
              "      <td>1.32360</td>\n",
              "      <td>1.32858</td>\n",
              "      <td>1.32220</td>\n",
              "      <td>1.32623</td>\n",
              "      <td>34613</td>\n",
              "      <td>1.28291</td>\n",
              "      <td>1.28422</td>\n",
              "      <td>1.27530</td>\n",
              "      <td>1.27560</td>\n",
              "      <td>32905</td>\n",
              "      <td>0.91716</td>\n",
              "      <td>0.92688</td>\n",
              "      <td>0.91656</td>\n",
              "      <td>0.92551</td>\n",
              "      <td>25926</td>\n",
              "      <td>112.863</td>\n",
              "      <td>113.552</td>\n",
              "      <td>112.846</td>\n",
              "      <td>113.484</td>\n",
              "      <td>51711</td>\n",
              "      <td>9.15248</td>\n",
              "      <td>9.16979</td>\n",
              "      <td>8.98850</td>\n",
              "      <td>9.08968</td>\n",
              "      <td>33157</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>2021.12.07</td>\n",
              "      <td>1996</td>\n",
              "      <td>1.12821</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>78783</td>\n",
              "      <td>1.32613</td>\n",
              "      <td>1.32890</td>\n",
              "      <td>1.32085</td>\n",
              "      <td>1.32419</td>\n",
              "      <td>33858</td>\n",
              "      <td>1.27557</td>\n",
              "      <td>1.27669</td>\n",
              "      <td>1.26347</td>\n",
              "      <td>1.26383</td>\n",
              "      <td>30074</td>\n",
              "      <td>0.92478</td>\n",
              "      <td>0.92748</td>\n",
              "      <td>0.92306</td>\n",
              "      <td>0.92486</td>\n",
              "      <td>24666</td>\n",
              "      <td>113.451</td>\n",
              "      <td>113.776</td>\n",
              "      <td>113.397</td>\n",
              "      <td>113.568</td>\n",
              "      <td>40041</td>\n",
              "      <td>9.07722</td>\n",
              "      <td>9.13943</td>\n",
              "      <td>9.04948</td>\n",
              "      <td>9.09611</td>\n",
              "      <td>34249</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12724</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.12704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               d  index     eu_o     eu_h     eu_l     eu_c    eu_v     gu_o  \\\n",
              "1992  2021.12.01   1992  1.13329  1.13594  1.13023  1.13190  122540  1.32967   \n",
              "1993  2021.12.02   1993  1.13191  1.13475  1.12952  1.13013   97454  1.32719   \n",
              "1994  2021.12.03   1994  1.13005  1.13333  1.12665  1.13088  113218  1.32970   \n",
              "1995  2021.12.06   1995  1.12997  1.13109  1.12664  1.12848   79067  1.32360   \n",
              "1996  2021.12.07   1996  1.12821  1.12982  1.12273  1.12681   78783  1.32613   \n",
              "\n",
              "         gu_h     gu_l     gu_c   gu_v     uc_o     uc_h     uc_l     uc_c  \\\n",
              "1992  1.33515  1.32612  1.32716  42174  1.27766  1.28293  1.27127  1.28225   \n",
              "1993  1.33331  1.32656  1.32998  37311  1.28133  1.28374  1.27780  1.28048   \n",
              "1994  1.33094  1.32081  1.32300  38625  1.28018  1.28536  1.27434  1.28488   \n",
              "1995  1.32858  1.32220  1.32623  34613  1.28291  1.28422  1.27530  1.27560   \n",
              "1996  1.32890  1.32085  1.32419  33858  1.27557  1.27669  1.26347  1.26383   \n",
              "\n",
              "       uc_v     uf_o     uf_h     uf_l     uf_c   uf_v     uj_o     uj_h  \\\n",
              "1992  39839  0.91832  0.92176  0.91690  0.92043  33483  113.087  113.625   \n",
              "1993  38280  0.91906  0.92213  0.91780  0.92023  28813  112.725  113.328   \n",
              "1994  38257  0.91998  0.92173  0.91655  0.91786  30287  113.003  113.610   \n",
              "1995  32905  0.91716  0.92688  0.91656  0.92551  25926  112.863  113.552   \n",
              "1996  30074  0.92478  0.92748  0.92306  0.92486  24666  113.451  113.776   \n",
              "\n",
              "         uj_l     uj_c   uj_v     us_o     us_h     us_l     us_c   us_v  \\\n",
              "1992  112.667  112.767  62416  9.00866  9.08965  8.99263  9.07443  41090   \n",
              "1993  112.698  113.185  58505  9.06588  9.09029  9.02448  9.04490  38791   \n",
              "1994  112.556  112.828  57050  9.03786  9.17935  9.03547  9.14200  38831   \n",
              "1995  112.846  113.484  51711  9.15248  9.16979  8.98850  9.08968  33157   \n",
              "1996  113.397  113.568  40041  9.07722  9.13943  9.04948  9.09611  34249   \n",
              "\n",
              "      eu_h_or_l  eu_c_vs_c  eu_High_next_day  eu_Low_next_day  \\\n",
              "1992          0          0           1.13475          1.12952   \n",
              "1993          1          0           1.13333          1.12665   \n",
              "1994          0          1           1.13109          1.12664   \n",
              "1995          0          0           1.12982          1.12273   \n",
              "1996          0          0           1.12724          1.12627   \n",
              "\n",
              "      eu_Close_next_day  \n",
              "1992            1.13013  \n",
              "1993            1.13088  \n",
              "1994            1.12848  \n",
              "1995            1.12681  \n",
              "1996            1.12704  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMLvjXAmBoSE",
        "outputId": "cee77a3b-f576-406b-f41f-e41c03c5f38b"
      },
      "source": [
        "\n",
        "df_m_5.isna().sum()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d                    0\n",
              "index                0\n",
              "eu_o                 0\n",
              "eu_h                 0\n",
              "eu_l                 0\n",
              "eu_c                 0\n",
              "eu_v                 0\n",
              "gu_o                 0\n",
              "gu_h                 0\n",
              "gu_l                 0\n",
              "gu_c                 0\n",
              "gu_v                 0\n",
              "uc_o                 0\n",
              "uc_h                 0\n",
              "uc_l                 0\n",
              "uc_c                 0\n",
              "uc_v                 0\n",
              "uf_o                 0\n",
              "uf_h                 0\n",
              "uf_l                 0\n",
              "uf_c                 0\n",
              "uf_v                 0\n",
              "uj_o                 0\n",
              "uj_h                 0\n",
              "uj_l                 0\n",
              "uj_c                 0\n",
              "uj_v                 0\n",
              "us_o                 0\n",
              "us_h                 0\n",
              "us_l                 0\n",
              "us_c                 0\n",
              "us_v                 0\n",
              "eu_h_or_l            0\n",
              "eu_c_vs_c            0\n",
              "eu_High_next_day     0\n",
              "eu_Low_next_day      0\n",
              "eu_Close_next_day    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEAMxmGyCWRB",
        "outputId": "f188ea63-8d1a-4eff-a455-f5c495d67d23"
      },
      "source": [
        "df_m_5.info()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1997 entries, 0 to 1996\n",
            "Data columns (total 37 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   d                  1997 non-null   object \n",
            " 1   index              1997 non-null   int64  \n",
            " 2   eu_o               1997 non-null   float64\n",
            " 3   eu_h               1997 non-null   float64\n",
            " 4   eu_l               1997 non-null   float64\n",
            " 5   eu_c               1997 non-null   float64\n",
            " 6   eu_v               1997 non-null   int64  \n",
            " 7   gu_o               1997 non-null   float64\n",
            " 8   gu_h               1997 non-null   float64\n",
            " 9   gu_l               1997 non-null   float64\n",
            " 10  gu_c               1997 non-null   float64\n",
            " 11  gu_v               1997 non-null   int64  \n",
            " 12  uc_o               1997 non-null   float64\n",
            " 13  uc_h               1997 non-null   float64\n",
            " 14  uc_l               1997 non-null   float64\n",
            " 15  uc_c               1997 non-null   float64\n",
            " 16  uc_v               1997 non-null   int64  \n",
            " 17  uf_o               1997 non-null   float64\n",
            " 18  uf_h               1997 non-null   float64\n",
            " 19  uf_l               1997 non-null   float64\n",
            " 20  uf_c               1997 non-null   float64\n",
            " 21  uf_v               1997 non-null   int64  \n",
            " 22  uj_o               1997 non-null   float64\n",
            " 23  uj_h               1997 non-null   float64\n",
            " 24  uj_l               1997 non-null   float64\n",
            " 25  uj_c               1997 non-null   float64\n",
            " 26  uj_v               1997 non-null   int64  \n",
            " 27  us_o               1997 non-null   float64\n",
            " 28  us_h               1997 non-null   float64\n",
            " 29  us_l               1997 non-null   float64\n",
            " 30  us_c               1997 non-null   float64\n",
            " 31  us_v               1997 non-null   int64  \n",
            " 32  eu_h_or_l          1997 non-null   int64  \n",
            " 33  eu_c_vs_c          1997 non-null   int64  \n",
            " 34  eu_High_next_day   1997 non-null   float64\n",
            " 35  eu_Low_next_day    1997 non-null   float64\n",
            " 36  eu_Close_next_day  1997 non-null   float64\n",
            "dtypes: float64(27), int64(9), object(1)\n",
            "memory usage: 592.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppP40BoAwFGk",
        "outputId": "1c94a241-72a7-432c-837d-e925b7fd0d52"
      },
      "source": [
        "#extract row for variable\n",
        "last_row = df_m_5.iloc[-1:,np.r_[1:34]].values\n",
        "print(last_row) "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.99600e+03 1.12821e+00 1.12982e+00 1.12273e+00 1.12681e+00 7.87830e+04\n",
            "  1.32613e+00 1.32890e+00 1.32085e+00 1.32419e+00 3.38580e+04 1.27557e+00\n",
            "  1.27669e+00 1.26347e+00 1.26383e+00 3.00740e+04 9.24780e-01 9.27480e-01\n",
            "  9.23060e-01 9.24860e-01 2.46660e+04 1.13451e+02 1.13776e+02 1.13397e+02\n",
            "  1.13568e+02 4.00410e+04 9.07722e+00 9.13943e+00 9.04948e+00 9.09611e+00\n",
            "  3.42490e+04 0.00000e+00 0.00000e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhfQ9UadZ1PE",
        "outputId": "38130e46-618e-424c-f158-21c163171151"
      },
      "source": [
        "#for high prediction\n",
        "#select rows to use for x,y\n",
        "x = df_m_5.iloc[:,np.r_[1:34]].values\n",
        "print(x)\n",
        "y = df_m_5.iloc[:,[34]].values\n",
        "print(y) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000e+00 1.38381e+00 1.38470e+00 ... 5.44310e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.00000e+00 1.38249e+00 1.38263e+00 ... 5.24030e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [2.00000e+00 1.37834e+00 1.37967e+00 ... 5.89320e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " ...\n",
            " [1.99400e+03 1.13005e+00 1.13333e+00 ... 3.88310e+04 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.99500e+03 1.12997e+00 1.13109e+00 ... 3.31570e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.99600e+03 1.12821e+00 1.12982e+00 ... 3.42490e+04 0.00000e+00\n",
            "  0.00000e+00]]\n",
            "[[1.38263]\n",
            " [1.37967]\n",
            " [1.37729]\n",
            " ...\n",
            " [1.13109]\n",
            " [1.12982]\n",
            " [1.12724]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqTW_s-u3g67"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v4b3tpQtg8_",
        "outputId": "d8a37d6b-698f-480c-a072-3d9ea6257c59"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=[\"xgboost\"], task=\"regression\", time_budget=600, eval_method=\"auto\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-07 23:47:05] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-07 23:47:05] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-07 23:47:05] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-07 23:47:05] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-07 23:47:05] {2071} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
            "[flaml.automl: 12-07 23:47:05] {2311} INFO - iteration 0, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:05] {2425} INFO - Estimated sufficient time budget=6182s. Estimated necessary time budget=6s.\n",
            "[flaml.automl: 12-07 23:47:05] {2505} INFO -  at 0.6s,\testimator xgboost's best error=38.6448,\tbest estimator xgboost's best error=38.6448\n",
            "[flaml.automl: 12-07 23:47:05] {2311} INFO - iteration 1, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 0.7s,\testimator xgboost's best error=38.6448,\tbest estimator xgboost's best error=38.6448\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 2, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 0.9s,\testimator xgboost's best error=8.1672,\tbest estimator xgboost's best error=8.1672\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 1.0s,\testimator xgboost's best error=0.0300,\tbest estimator xgboost's best error=0.0300\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 1.1s,\testimator xgboost's best error=0.0300,\tbest estimator xgboost's best error=0.0300\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 1.2s,\testimator xgboost's best error=0.0300,\tbest estimator xgboost's best error=0.0300\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 1.4s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 7, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:06] {2505} INFO -  at 1.6s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
            "[flaml.automl: 12-07 23:47:06] {2311} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:07] {2505} INFO -  at 1.7s,\testimator xgboost's best error=0.0146,\tbest estimator xgboost's best error=0.0146\n",
            "[flaml.automl: 12-07 23:47:07] {2311} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:07] {2505} INFO -  at 1.9s,\testimator xgboost's best error=0.0099,\tbest estimator xgboost's best error=0.0099\n",
            "[flaml.automl: 12-07 23:47:07] {2311} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:07] {2505} INFO -  at 2.1s,\testimator xgboost's best error=0.0099,\tbest estimator xgboost's best error=0.0099\n",
            "[flaml.automl: 12-07 23:47:07] {2311} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:07] {2505} INFO -  at 2.3s,\testimator xgboost's best error=0.0099,\tbest estimator xgboost's best error=0.0099\n",
            "[flaml.automl: 12-07 23:47:07] {2311} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:07] {2505} INFO -  at 2.5s,\testimator xgboost's best error=0.0093,\tbest estimator xgboost's best error=0.0093\n",
            "[flaml.automl: 12-07 23:47:07] {2311} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:08] {2505} INFO -  at 2.7s,\testimator xgboost's best error=0.0093,\tbest estimator xgboost's best error=0.0093\n",
            "[flaml.automl: 12-07 23:47:08] {2311} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:08] {2505} INFO -  at 3.0s,\testimator xgboost's best error=0.0066,\tbest estimator xgboost's best error=0.0066\n",
            "[flaml.automl: 12-07 23:47:08] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:08] {2505} INFO -  at 3.3s,\testimator xgboost's best error=0.0066,\tbest estimator xgboost's best error=0.0066\n",
            "[flaml.automl: 12-07 23:47:08] {2311} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:09] {2505} INFO -  at 3.7s,\testimator xgboost's best error=0.0060,\tbest estimator xgboost's best error=0.0060\n",
            "[flaml.automl: 12-07 23:47:09] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:09] {2505} INFO -  at 4.0s,\testimator xgboost's best error=0.0060,\tbest estimator xgboost's best error=0.0060\n",
            "[flaml.automl: 12-07 23:47:09] {2311} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:10] {2505} INFO -  at 4.7s,\testimator xgboost's best error=0.0045,\tbest estimator xgboost's best error=0.0045\n",
            "[flaml.automl: 12-07 23:47:10] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:10] {2505} INFO -  at 5.0s,\testimator xgboost's best error=0.0045,\tbest estimator xgboost's best error=0.0045\n",
            "[flaml.automl: 12-07 23:47:10] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:12] {2505} INFO -  at 6.9s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:12] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:13] {2505} INFO -  at 7.9s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:13] {2311} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:13] {2505} INFO -  at 8.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:13] {2311} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:14] {2505} INFO -  at 8.8s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:14] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:16] {2505} INFO -  at 10.8s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:16] {2311} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:16] {2505} INFO -  at 11.3s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:16] {2311} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:19] {2505} INFO -  at 13.7s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:19] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:19] {2505} INFO -  at 14.5s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:19] {2311} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:21] {2505} INFO -  at 16.6s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:21] {2311} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:22] {2505} INFO -  at 17.0s,\testimator xgboost's best error=0.0044,\tbest estimator xgboost's best error=0.0044\n",
            "[flaml.automl: 12-07 23:47:22] {2311} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:30] {2505} INFO -  at 25.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:47:30] {2311} INFO - iteration 31, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:34] {2505} INFO -  at 29.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:47:34] {2311} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:40] {2505} INFO -  at 34.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:47:40] {2311} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:45] {2505} INFO -  at 39.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:47:45] {2311} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-07 23:47:51] {2505} INFO -  at 46.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:47:51] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:00] {2505} INFO -  at 55.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:00] {2311} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:01] {2505} INFO -  at 55.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:01] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:04] {2505} INFO -  at 59.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:04] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:09] {2505} INFO -  at 63.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:09] {2311} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:12] {2505} INFO -  at 67.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:12] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:15] {2505} INFO -  at 70.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:15] {2311} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:19] {2505} INFO -  at 74.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:19] {2311} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:28] {2505} INFO -  at 83.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:28] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:30] {2505} INFO -  at 85.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:30] {2311} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:33] {2505} INFO -  at 88.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:33] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:36] {2505} INFO -  at 90.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:36] {2311} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:41] {2505} INFO -  at 96.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:41] {2311} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:44] {2505} INFO -  at 98.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:44] {2311} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:52] {2505} INFO -  at 106.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:52] {2311} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 12-07 23:48:59] {2505} INFO -  at 114.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:48:59] {2311} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:03] {2505} INFO -  at 117.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:03] {2311} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:18] {2505} INFO -  at 133.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:18] {2311} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:21] {2505} INFO -  at 136.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:21] {2311} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:29] {2505} INFO -  at 144.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:29] {2311} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:35] {2505} INFO -  at 150.5s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:35] {2311} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:41] {2505} INFO -  at 156.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:41] {2311} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 12-07 23:49:46] {2505} INFO -  at 161.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:49:46] {2311} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:02] {2505} INFO -  at 177.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:02] {2311} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:05] {2505} INFO -  at 180.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:05] {2311} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:10] {2505} INFO -  at 184.7s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:10] {2311} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:21] {2505} INFO -  at 196.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:21] {2311} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:30] {2505} INFO -  at 205.5s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:30] {2311} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:35] {2505} INFO -  at 210.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:35] {2311} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:43] {2505} INFO -  at 218.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:43] {2311} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:51] {2505} INFO -  at 225.7s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:51] {2311} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 12-07 23:50:52] {2505} INFO -  at 227.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:50:52] {2311} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 12-07 23:51:22] {2505} INFO -  at 257.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:51:22] {2311} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 12-07 23:51:31] {2505} INFO -  at 265.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:51:31] {2311} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 12-07 23:51:34] {2505} INFO -  at 269.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:51:34] {2311} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 12-07 23:51:46] {2505} INFO -  at 281.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:51:46] {2311} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 12-07 23:51:49] {2505} INFO -  at 284.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:51:49] {2311} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:00] {2505} INFO -  at 294.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:00] {2311} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:04] {2505} INFO -  at 299.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:04] {2311} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:13] {2505} INFO -  at 307.7s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:13] {2311} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:18] {2505} INFO -  at 313.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:18] {2311} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:23] {2505} INFO -  at 318.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:23] {2311} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:31] {2505} INFO -  at 326.0s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:31] {2311} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:34] {2505} INFO -  at 329.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:34] {2311} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:37] {2505} INFO -  at 331.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:37] {2311} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:47] {2505} INFO -  at 342.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:47] {2311} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:54] {2505} INFO -  at 349.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:54] {2311} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 12-07 23:52:59] {2505} INFO -  at 354.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:52:59] {2311} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:04] {2505} INFO -  at 358.8s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:04] {2311} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:12] {2505} INFO -  at 367.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:12] {2311} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:16] {2505} INFO -  at 371.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:16] {2311} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:20] {2505} INFO -  at 375.4s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:20] {2311} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:29] {2505} INFO -  at 384.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:29] {2311} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:34] {2505} INFO -  at 389.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:34] {2311} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:36] {2505} INFO -  at 391.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:36] {2311} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:42] {2505} INFO -  at 396.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:42] {2311} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:47] {2505} INFO -  at 401.7s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:47] {2311} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:51] {2505} INFO -  at 405.7s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:51] {2311} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:53] {2505} INFO -  at 408.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:53] {2311} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 12-07 23:53:56] {2505} INFO -  at 411.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:53:56] {2311} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:08] {2505} INFO -  at 423.6s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:54:08] {2311} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:15] {2505} INFO -  at 430.1s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:54:15] {2311} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:18] {2505} INFO -  at 432.9s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:54:18] {2311} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:23] {2505} INFO -  at 438.3s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:54:23] {2311} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:35] {2505} INFO -  at 450.2s,\testimator xgboost's best error=0.0039,\tbest estimator xgboost's best error=0.0039\n",
            "[flaml.automl: 12-07 23:54:35] {2311} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:48] {2505} INFO -  at 462.9s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-07 23:54:48] {2311} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 12-07 23:54:58] {2505} INFO -  at 473.0s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-07 23:54:58] {2311} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 12-07 23:55:28] {2505} INFO -  at 503.3s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-07 23:55:28] {2311} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 12-07 23:55:37] {2505} INFO -  at 511.9s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-07 23:55:37] {2311} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 12-07 23:55:51] {2505} INFO -  at 525.9s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:55:51] {2311} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 12-07 23:56:09] {2505} INFO -  at 543.8s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:56:09] {2311} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 12-07 23:56:14] {2505} INFO -  at 548.7s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:56:14] {2311} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 12-07 23:56:32] {2505} INFO -  at 567.6s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:56:32] {2311} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 12-07 23:56:40] {2505} INFO -  at 575.6s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:56:40] {2311} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 12-07 23:57:10] {2505} INFO -  at 605.1s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-07 23:57:13] {2717} INFO - retrain xgboost for 3.2s\n",
            "[flaml.automl: 12-07 23:57:13] {2722} INFO - retrained model: XGBRegressor(colsample_bylevel=0.7735847515513625, colsample_bytree=1.0,\n",
            "             grow_policy='lossguide', learning_rate=0.01578582627082461,\n",
            "             max_depth=0, max_leaves=14, min_child_weight=1.107304504895782,\n",
            "             n_estimators=907, n_jobs=-1, reg_alpha=0.010153693558416055,\n",
            "             reg_lambda=0.034966802423285405, subsample=1.0, tree_method='hist',\n",
            "             use_label_encoder=False, verbosity=0)\n",
            "[flaml.automl: 12-07 23:57:13] {2100} INFO - fit succeeded\n",
            "[flaml.automl: 12-07 23:57:13] {2102} INFO - Time taken to find the best model: 525.9458813667297\n",
            "[flaml.automl: 12-07 23:57:13] {2116} WARNING - Time taken to find the best model is 88% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5yHztyhnm3x",
        "outputId": "a5eb5d8f-030b-4908-8c41-895cb8284f31"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "#paste retrained model\n",
        "sugg_reg_high_param = XGBRegressor(colsample_bylevel=0.7735847515513625, colsample_bytree=1.0,\n",
        "             grow_policy='lossguide', learning_rate=0.01578582627082461,\n",
        "             max_depth=0, max_leaves=14, min_child_weight=1.107304504895782,\n",
        "             n_estimators=907, n_jobs=-1, reg_alpha=0.010153693558416055,\n",
        "             reg_lambda=0.034966802423285405, subsample=1.0, tree_method='hist',\n",
        "             use_label_encoder=False, verbosity=0)\n",
        "#paste finished\n",
        "sugg_reg_high_param.fit(X_train,y_train)\n",
        "y_pred_h=sugg_reg_high_param.predict(last_row)\n",
        "y_pred_h"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.1282575], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmHBSVwEPp5t"
      },
      "source": [
        "y_pred = sugg_reg_high_param.predict(X_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4bGcB9U62Js"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true,y_pred):\n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suK5rCpV0p9g",
        "outputId": "5dd74aa0-8ba7-4bf9-f9a6-451bf88c4e34"
      },
      "source": [
        "#for regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.002974342013804116\n",
            "MSE: 1.7577455865652052e-05\n",
            "RMSE: 0.004192547658125313\n",
            "MAPE: 6.24064703490447\n",
            "MedAE 0.002272793540954554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIHV30_ZH5eg",
        "outputId": "8f5b3faf-ab9c-4ab0-cfab-d0b28626f03a"
      },
      "source": [
        "#for low prediction\n",
        "#select rows to use for x,y\n",
        "x = df_m_5.iloc[:,np.r_[1:34]].values\n",
        "print(x)\n",
        "y = df_m_5.iloc[:,[35]].values\n",
        "print(y) "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000e+00 1.38381e+00 1.38470e+00 ... 5.44310e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.00000e+00 1.38249e+00 1.38263e+00 ... 5.24030e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [2.00000e+00 1.37834e+00 1.37967e+00 ... 5.89320e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " ...\n",
            " [1.99400e+03 1.13005e+00 1.13333e+00 ... 3.88310e+04 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.99500e+03 1.12997e+00 1.13109e+00 ... 3.31570e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.99600e+03 1.12821e+00 1.12982e+00 ... 3.42490e+04 0.00000e+00\n",
            "  0.00000e+00]]\n",
            "[[1.37762]\n",
            " [1.37283]\n",
            " [1.37047]\n",
            " ...\n",
            " [1.12664]\n",
            " [1.12273]\n",
            " [1.12627]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-d3TjyWS22Q"
      },
      "source": [
        "#for low prediction\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81686f16-10b6-473e-8b00-5f928a4d97ce",
        "id": "9WTZr86wX-dR"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=[\"xgboost\"], task=\"regression\", time_budget=600, eval_method=\"auto\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-08 00:10:00] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-08 00:10:00] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-08 00:10:00] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-08 00:10:00] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-08 00:10:00] {2071} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
            "[flaml.automl: 12-08 00:10:00] {2311} INFO - iteration 0, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:00] {2425} INFO - Estimated sufficient time budget=1148s. Estimated necessary time budget=1s.\n",
            "[flaml.automl: 12-08 00:10:00] {2505} INFO -  at 0.1s,\testimator xgboost's best error=37.8716,\tbest estimator xgboost's best error=37.8716\n",
            "[flaml.automl: 12-08 00:10:00] {2311} INFO - iteration 1, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:00] {2505} INFO -  at 0.2s,\testimator xgboost's best error=37.8716,\tbest estimator xgboost's best error=37.8716\n",
            "[flaml.automl: 12-08 00:10:00] {2311} INFO - iteration 2, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 0.4s,\testimator xgboost's best error=8.0367,\tbest estimator xgboost's best error=8.0367\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 0.5s,\testimator xgboost's best error=0.0233,\tbest estimator xgboost's best error=0.0233\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 0.6s,\testimator xgboost's best error=0.0233,\tbest estimator xgboost's best error=0.0233\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 0.7s,\testimator xgboost's best error=0.0233,\tbest estimator xgboost's best error=0.0233\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 0.9s,\testimator xgboost's best error=0.0147,\tbest estimator xgboost's best error=0.0147\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 7, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 1.1s,\testimator xgboost's best error=0.0129,\tbest estimator xgboost's best error=0.0129\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:01] {2505} INFO -  at 1.3s,\testimator xgboost's best error=0.0129,\tbest estimator xgboost's best error=0.0129\n",
            "[flaml.automl: 12-08 00:10:01] {2311} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:02] {2505} INFO -  at 1.5s,\testimator xgboost's best error=0.0096,\tbest estimator xgboost's best error=0.0096\n",
            "[flaml.automl: 12-08 00:10:02] {2311} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:02] {2505} INFO -  at 1.6s,\testimator xgboost's best error=0.0096,\tbest estimator xgboost's best error=0.0096\n",
            "[flaml.automl: 12-08 00:10:02] {2311} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:02] {2505} INFO -  at 1.8s,\testimator xgboost's best error=0.0096,\tbest estimator xgboost's best error=0.0096\n",
            "[flaml.automl: 12-08 00:10:02] {2311} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:02] {2505} INFO -  at 2.1s,\testimator xgboost's best error=0.0096,\tbest estimator xgboost's best error=0.0096\n",
            "[flaml.automl: 12-08 00:10:02] {2311} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:02] {2505} INFO -  at 2.3s,\testimator xgboost's best error=0.0096,\tbest estimator xgboost's best error=0.0096\n",
            "[flaml.automl: 12-08 00:10:02] {2311} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:03] {2505} INFO -  at 2.5s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:03] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:03] {2505} INFO -  at 2.7s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:03] {2311} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:03] {2505} INFO -  at 3.0s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:03] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:03] {2505} INFO -  at 3.2s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:03] {2311} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:04] {2505} INFO -  at 3.6s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:04] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:04] {2505} INFO -  at 3.7s,\testimator xgboost's best error=0.0076,\tbest estimator xgboost's best error=0.0076\n",
            "[flaml.automl: 12-08 00:10:04] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:04] {2505} INFO -  at 4.3s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:04] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:05] {2505} INFO -  at 4.7s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:05] {2311} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:05] {2505} INFO -  at 5.0s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:05] {2311} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:05] {2505} INFO -  at 5.1s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:05] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:06] {2505} INFO -  at 5.9s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:06] {2311} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:06] {2505} INFO -  at 6.1s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:06] {2311} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:07] {2505} INFO -  at 7.1s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:07] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:07] {2505} INFO -  at 7.3s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:07] {2311} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:08] {2505} INFO -  at 8.0s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:08] {2311} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:08] {2505} INFO -  at 8.2s,\testimator xgboost's best error=0.0058,\tbest estimator xgboost's best error=0.0058\n",
            "[flaml.automl: 12-08 00:10:08] {2311} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:10] {2505} INFO -  at 9.8s,\testimator xgboost's best error=0.0046,\tbest estimator xgboost's best error=0.0046\n",
            "[flaml.automl: 12-08 00:10:10] {2311} INFO - iteration 31, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:11] {2505} INFO -  at 10.6s,\testimator xgboost's best error=0.0046,\tbest estimator xgboost's best error=0.0046\n",
            "[flaml.automl: 12-08 00:10:11] {2311} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:12] {2505} INFO -  at 12.0s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:12] {2311} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:14] {2505} INFO -  at 13.7s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:14] {2311} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:15] {2505} INFO -  at 14.9s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:15] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:19] {2505} INFO -  at 19.1s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:19] {2311} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:20] {2505} INFO -  at 19.4s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:20] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:21] {2505} INFO -  at 20.7s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:21] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:22] {2505} INFO -  at 22.0s,\testimator xgboost's best error=0.0042,\tbest estimator xgboost's best error=0.0042\n",
            "[flaml.automl: 12-08 00:10:22] {2311} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:24] {2505} INFO -  at 23.5s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:24] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:25] {2505} INFO -  at 24.9s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:25] {2311} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:26] {2505} INFO -  at 25.8s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:26] {2311} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:28] {2505} INFO -  at 27.4s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:28] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:29] {2505} INFO -  at 28.4s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:29] {2311} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:30] {2505} INFO -  at 29.4s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:30] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:32] {2505} INFO -  at 31.4s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:32] {2311} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:32] {2505} INFO -  at 32.2s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:32] {2311} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:33] {2505} INFO -  at 33.1s,\testimator xgboost's best error=0.0038,\tbest estimator xgboost's best error=0.0038\n",
            "[flaml.automl: 12-08 00:10:33] {2311} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:35] {2505} INFO -  at 34.9s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-08 00:10:35] {2311} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:40] {2505} INFO -  at 39.5s,\testimator xgboost's best error=0.0036,\tbest estimator xgboost's best error=0.0036\n",
            "[flaml.automl: 12-08 00:10:40] {2311} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:43] {2505} INFO -  at 43.1s,\testimator xgboost's best error=0.0035,\tbest estimator xgboost's best error=0.0035\n",
            "[flaml.automl: 12-08 00:10:43] {2311} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:52] {2505} INFO -  at 51.6s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:10:52] {2311} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 12-08 00:10:55] {2505} INFO -  at 55.3s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:10:55] {2311} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:04] {2505} INFO -  at 63.7s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:04] {2311} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:12] {2505} INFO -  at 71.8s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:12] {2311} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:21] {2505} INFO -  at 81.1s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:21] {2311} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:28] {2505} INFO -  at 87.7s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:28] {2311} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:52] {2505} INFO -  at 111.7s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:52] {2311} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 12-08 00:11:55] {2505} INFO -  at 115.1s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:11:55] {2311} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:00] {2505} INFO -  at 119.5s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:12:00] {2311} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:16] {2505} INFO -  at 136.3s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:12:16] {2311} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:23] {2505} INFO -  at 143.2s,\testimator xgboost's best error=0.0034,\tbest estimator xgboost's best error=0.0034\n",
            "[flaml.automl: 12-08 00:12:23] {2311} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:30] {2505} INFO -  at 149.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:12:30] {2311} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:38] {2505} INFO -  at 157.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:12:38] {2311} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:44] {2505} INFO -  at 164.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:12:44] {2311} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 12-08 00:12:46] {2505} INFO -  at 165.8s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:12:46] {2311} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:14] {2505} INFO -  at 193.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:14] {2311} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:21] {2505} INFO -  at 200.8s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:21] {2311} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:25] {2505} INFO -  at 205.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:25] {2311} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:41] {2505} INFO -  at 221.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:41] {2311} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:44] {2505} INFO -  at 223.7s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:44] {2311} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:54] {2505} INFO -  at 233.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:54] {2311} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 12-08 00:13:57] {2505} INFO -  at 237.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:13:57] {2311} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:07] {2505} INFO -  at 246.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:07] {2311} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:11] {2505} INFO -  at 250.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:11] {2311} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:15] {2505} INFO -  at 255.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:15] {2311} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:25] {2505} INFO -  at 265.0s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:25] {2311} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:32] {2505} INFO -  at 272.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:32] {2311} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:34] {2505} INFO -  at 274.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:34] {2311} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:42] {2505} INFO -  at 281.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:42] {2311} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:47] {2505} INFO -  at 287.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:47] {2311} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 12-08 00:14:51] {2505} INFO -  at 291.0s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:14:51] {2311} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:00] {2505} INFO -  at 299.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:00] {2311} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:06] {2505} INFO -  at 306.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:06] {2311} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:13] {2505} INFO -  at 312.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:13] {2311} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:16] {2505} INFO -  at 315.8s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:16] {2311} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:30] {2505} INFO -  at 329.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:30] {2311} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:39] {2505} INFO -  at 339.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:39] {2311} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:42] {2505} INFO -  at 341.4s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:42] {2311} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:52] {2505} INFO -  at 351.7s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:52] {2311} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 12-08 00:15:55] {2505} INFO -  at 354.4s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:15:55] {2311} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:02] {2505} INFO -  at 362.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:02] {2311} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:06] {2505} INFO -  at 365.4s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:06] {2311} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:11] {2505} INFO -  at 371.0s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:11] {2311} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:19] {2505} INFO -  at 378.6s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:19] {2311} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:28] {2505} INFO -  at 387.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:28] {2311} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:30] {2505} INFO -  at 389.8s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:30] {2311} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:33] {2505} INFO -  at 393.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:33] {2311} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:44] {2505} INFO -  at 404.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:44] {2311} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 12-08 00:16:57] {2505} INFO -  at 416.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:16:57] {2311} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 12-08 00:17:04] {2505} INFO -  at 423.6s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:17:04] {2311} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 12-08 00:17:25] {2505} INFO -  at 444.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:17:25] {2311} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 12-08 00:17:30] {2505} INFO -  at 450.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:17:30] {2311} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 12-08 00:17:41] {2505} INFO -  at 461.0s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:17:41] {2311} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 12-08 00:17:54] {2505} INFO -  at 473.5s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:17:54] {2311} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 12-08 00:18:00] {2505} INFO -  at 479.8s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:18:00] {2311} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 12-08 00:18:15] {2505} INFO -  at 494.6s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:18:15] {2311} INFO - iteration 107, current learner xgboost\n",
            "[flaml.automl: 12-08 00:18:21] {2505} INFO -  at 501.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:18:21] {2311} INFO - iteration 108, current learner xgboost\n",
            "[flaml.automl: 12-08 00:18:39] {2505} INFO -  at 518.7s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:18:39] {2311} INFO - iteration 109, current learner xgboost\n",
            "[flaml.automl: 12-08 00:18:49] {2505} INFO -  at 529.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:18:49] {2311} INFO - iteration 110, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:00] {2505} INFO -  at 539.9s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:00] {2311} INFO - iteration 111, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:03] {2505} INFO -  at 543.2s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:03] {2311} INFO - iteration 112, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:11] {2505} INFO -  at 551.1s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:11] {2311} INFO - iteration 113, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:15] {2505} INFO -  at 555.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:15] {2311} INFO - iteration 114, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:18] {2505} INFO -  at 558.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:18] {2311} INFO - iteration 115, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:23] {2505} INFO -  at 563.3s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:23] {2311} INFO - iteration 116, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:38] {2505} INFO -  at 578.0s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:38] {2311} INFO - iteration 117, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:46] {2505} INFO -  at 585.7s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:46] {2311} INFO - iteration 118, current learner xgboost\n",
            "[flaml.automl: 12-08 00:19:56] {2505} INFO -  at 595.4s,\testimator xgboost's best error=0.0033,\tbest estimator xgboost's best error=0.0033\n",
            "[flaml.automl: 12-08 00:19:58] {2717} INFO - retrain xgboost for 2.3s\n",
            "[flaml.automl: 12-08 00:19:58] {2722} INFO - retrained model: XGBRegressor(colsample_bylevel=0.9592879588141041, colsample_bytree=1.0,\n",
            "             grow_policy='lossguide', learning_rate=0.013488593217061895,\n",
            "             max_depth=0, max_leaves=5, min_child_weight=0.43462849479807825,\n",
            "             n_estimators=1038, n_jobs=-1, reg_alpha=0.02182073928249339,\n",
            "             reg_lambda=0.36764156052221886, subsample=0.9211577277604256,\n",
            "             tree_method='hist', use_label_encoder=False, verbosity=0)\n",
            "[flaml.automl: 12-08 00:19:58] {2100} INFO - fit succeeded\n",
            "[flaml.automl: 12-08 00:19:58] {2102} INFO - Time taken to find the best model: 460.97672939300537\n",
            "[flaml.automl: 12-08 00:19:58] {2116} WARNING - Time taken to find the best model is 77% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd12546-b8d1-40e2-e673-b431b93b8a3c",
        "id": "bUIrv_D8YMFA"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "#paste retrained model\n",
        "sugg_reg_low_param = XGBRegressor(colsample_bylevel=0.9592879588141041, colsample_bytree=1.0,\n",
        "             grow_policy='lossguide', learning_rate=0.013488593217061895,\n",
        "             max_depth=0, max_leaves=5, min_child_weight=0.43462849479807825,\n",
        "             n_estimators=1038, n_jobs=-1, reg_alpha=0.02182073928249339,\n",
        "             reg_lambda=0.36764156052221886, subsample=0.9211577277604256,\n",
        "             tree_method='hist', use_label_encoder=False, verbosity=0)\n",
        "#paste finished\n",
        "sugg_reg_low_param.fit(X_train,y_train)\n",
        "y_pred_l=sugg_reg_low_param.predict(last_row)\n",
        "y_pred_l"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.1232481], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSflbgeHS22R"
      },
      "source": [
        "#for low pred \n",
        "y_pred = sugg_reg_low_param.predict(X_test)\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlEpAY7S22R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b473517-2188-4df0-ac6b-e8d8913df77c"
      },
      "source": [
        "#for low pred regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.0029246597786585444\n",
            "MSE: 1.6349558016580218e-05\n",
            "RMSE: 0.004043458670071974\n",
            "MAPE: 6.448148457319131\n",
            "MedAE 0.00225603111267092\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNQOZ0oNIwHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "137d1623-6f5f-47cd-a3b0-4d586a0bf98d"
      },
      "source": [
        "#for close prediction\n",
        "#select rows to use for x,y\n",
        "x = df_m_5.iloc[:,np.r_[1:34]].values\n",
        "print(x)\n",
        "y = df_m_5.iloc[:,[36]].values\n",
        "print(y) "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00000e+00 1.38381e+00 1.38470e+00 ... 5.44310e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.00000e+00 1.38249e+00 1.38263e+00 ... 5.24030e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [2.00000e+00 1.37834e+00 1.37967e+00 ... 5.89320e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " ...\n",
            " [1.99400e+03 1.13005e+00 1.13333e+00 ... 3.88310e+04 0.00000e+00\n",
            "  1.00000e+00]\n",
            " [1.99500e+03 1.12997e+00 1.13109e+00 ... 3.31570e+04 0.00000e+00\n",
            "  0.00000e+00]\n",
            " [1.99600e+03 1.12821e+00 1.12982e+00 ... 3.42490e+04 0.00000e+00\n",
            "  0.00000e+00]]\n",
            "[[1.3783 ]\n",
            " [1.37437]\n",
            " [1.37513]\n",
            " ...\n",
            " [1.12848]\n",
            " [1.12681]\n",
            " [1.12704]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEJIyPqMViu4"
      },
      "source": [
        "#for close prediction\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e90923d-e14a-4e21-c25f-c714df31ad77",
        "id": "PdLGMtbGb8ZI"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=[\"xgboost\"], task=\"regression\", time_budget=600, eval_method=\"auto\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-08 00:27:31] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-08 00:27:31] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-08 00:27:31] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-08 00:27:31] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-08 00:27:31] {2071} INFO - List of ML learners in AutoML Run: ['xgboost']\n",
            "[flaml.automl: 12-08 00:27:31] {2311} INFO - iteration 0, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:31] {2425} INFO - Estimated sufficient time budget=1007s. Estimated necessary time budget=1s.\n",
            "[flaml.automl: 12-08 00:27:31] {2505} INFO -  at 0.1s,\testimator xgboost's best error=39.4932,\tbest estimator xgboost's best error=39.4932\n",
            "[flaml.automl: 12-08 00:27:31] {2311} INFO - iteration 1, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:31] {2505} INFO -  at 0.2s,\testimator xgboost's best error=39.4932,\tbest estimator xgboost's best error=39.4932\n",
            "[flaml.automl: 12-08 00:27:31] {2311} INFO - iteration 2, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:31] {2505} INFO -  at 0.3s,\testimator xgboost's best error=8.3539,\tbest estimator xgboost's best error=8.3539\n",
            "[flaml.automl: 12-08 00:27:31] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:31] {2505} INFO -  at 0.4s,\testimator xgboost's best error=0.0364,\tbest estimator xgboost's best error=0.0364\n",
            "[flaml.automl: 12-08 00:27:31] {2311} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 0.6s,\testimator xgboost's best error=0.0364,\tbest estimator xgboost's best error=0.0364\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 5, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 0.7s,\testimator xgboost's best error=0.0364,\tbest estimator xgboost's best error=0.0364\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 6, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 0.8s,\testimator xgboost's best error=0.0192,\tbest estimator xgboost's best error=0.0192\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 7, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 1.0s,\testimator xgboost's best error=0.0182,\tbest estimator xgboost's best error=0.0182\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 8, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 1.2s,\testimator xgboost's best error=0.0182,\tbest estimator xgboost's best error=0.0182\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:32] {2505} INFO -  at 1.4s,\testimator xgboost's best error=0.0128,\tbest estimator xgboost's best error=0.0128\n",
            "[flaml.automl: 12-08 00:27:32] {2311} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:33] {2505} INFO -  at 1.6s,\testimator xgboost's best error=0.0128,\tbest estimator xgboost's best error=0.0128\n",
            "[flaml.automl: 12-08 00:27:33] {2311} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:33] {2505} INFO -  at 1.8s,\testimator xgboost's best error=0.0128,\tbest estimator xgboost's best error=0.0128\n",
            "[flaml.automl: 12-08 00:27:33] {2311} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:33] {2505} INFO -  at 2.1s,\testimator xgboost's best error=0.0128,\tbest estimator xgboost's best error=0.0128\n",
            "[flaml.automl: 12-08 00:27:33] {2311} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:33] {2505} INFO -  at 2.3s,\testimator xgboost's best error=0.0128,\tbest estimator xgboost's best error=0.0128\n",
            "[flaml.automl: 12-08 00:27:33] {2311} INFO - iteration 14, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:34] {2505} INFO -  at 2.6s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:34] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:34] {2505} INFO -  at 2.7s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:34] {2311} INFO - iteration 16, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:34] {2505} INFO -  at 3.1s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:34] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:34] {2505} INFO -  at 3.2s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:34] {2311} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:35] {2505} INFO -  at 3.6s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:35] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:35] {2505} INFO -  at 3.7s,\testimator xgboost's best error=0.0111,\tbest estimator xgboost's best error=0.0111\n",
            "[flaml.automl: 12-08 00:27:35] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:35] {2505} INFO -  at 4.3s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:35] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:36] {2505} INFO -  at 4.7s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:36] {2311} INFO - iteration 22, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:36] {2505} INFO -  at 5.0s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:36] {2311} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:36] {2505} INFO -  at 5.1s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:36] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:37] {2505} INFO -  at 5.9s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:37] {2311} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:37] {2505} INFO -  at 6.1s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:37] {2311} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:38] {2505} INFO -  at 7.2s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:38] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:38] {2505} INFO -  at 7.4s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:38] {2311} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:39] {2505} INFO -  at 8.1s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:39] {2311} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:39] {2505} INFO -  at 8.4s,\testimator xgboost's best error=0.0098,\tbest estimator xgboost's best error=0.0098\n",
            "[flaml.automl: 12-08 00:27:39] {2311} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:41] {2505} INFO -  at 10.1s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:41] {2311} INFO - iteration 31, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:42] {2505} INFO -  at 10.9s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:42] {2311} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:43] {2505} INFO -  at 12.4s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:43] {2311} INFO - iteration 33, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:44] {2505} INFO -  at 13.3s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:44] {2311} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:46] {2505} INFO -  at 15.0s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:46] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:52] {2505} INFO -  at 20.7s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:52] {2311} INFO - iteration 36, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:52] {2505} INFO -  at 20.9s,\testimator xgboost's best error=0.0085,\tbest estimator xgboost's best error=0.0085\n",
            "[flaml.automl: 12-08 00:27:52] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:54] {2505} INFO -  at 23.0s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:27:54] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:56] {2505} INFO -  at 24.6s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:27:56] {2311} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:56] {2505} INFO -  at 25.3s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:27:56] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-08 00:27:58] {2505} INFO -  at 27.3s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:27:58] {2311} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:00] {2505} INFO -  at 28.6s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:00] {2311} INFO - iteration 42, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:00] {2505} INFO -  at 29.4s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:00] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:01] {2505} INFO -  at 29.8s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:01] {2311} INFO - iteration 44, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:02] {2505} INFO -  at 31.4s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:02] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:04] {2505} INFO -  at 32.5s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:04] {2311} INFO - iteration 46, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:05] {2505} INFO -  at 34.0s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:05] {2311} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:06] {2505} INFO -  at 34.5s,\testimator xgboost's best error=0.0079,\tbest estimator xgboost's best error=0.0079\n",
            "[flaml.automl: 12-08 00:28:06] {2311} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:08] {2505} INFO -  at 36.6s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:08] {2311} INFO - iteration 49, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:10] {2505} INFO -  at 39.2s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:10] {2311} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:12] {2505} INFO -  at 41.3s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:12] {2311} INFO - iteration 51, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:17] {2505} INFO -  at 46.0s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:17] {2311} INFO - iteration 52, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:18] {2505} INFO -  at 47.3s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:18] {2311} INFO - iteration 53, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:22] {2505} INFO -  at 51.2s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:22] {2311} INFO - iteration 54, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:24] {2505} INFO -  at 53.3s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:24] {2311} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:26] {2505} INFO -  at 54.6s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:26] {2311} INFO - iteration 56, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:28] {2505} INFO -  at 56.8s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:28] {2311} INFO - iteration 57, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:33] {2505} INFO -  at 62.2s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:33] {2311} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:35] {2505} INFO -  at 63.7s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:35] {2311} INFO - iteration 59, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:36] {2505} INFO -  at 65.3s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:36] {2311} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:41] {2505} INFO -  at 70.0s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:41] {2311} INFO - iteration 61, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:46] {2505} INFO -  at 74.5s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:46] {2311} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:47] {2505} INFO -  at 76.3s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:47] {2311} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:50] {2505} INFO -  at 79.2s,\testimator xgboost's best error=0.0075,\tbest estimator xgboost's best error=0.0075\n",
            "[flaml.automl: 12-08 00:28:50] {2311} INFO - iteration 64, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:52] {2505} INFO -  at 81.2s,\testimator xgboost's best error=0.0073,\tbest estimator xgboost's best error=0.0073\n",
            "[flaml.automl: 12-08 00:28:52] {2311} INFO - iteration 65, current learner xgboost\n",
            "[flaml.automl: 12-08 00:28:53] {2505} INFO -  at 82.0s,\testimator xgboost's best error=0.0073,\tbest estimator xgboost's best error=0.0073\n",
            "[flaml.automl: 12-08 00:28:53] {2311} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:01] {2505} INFO -  at 90.3s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:01] {2311} INFO - iteration 67, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:13] {2505} INFO -  at 102.3s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:13] {2311} INFO - iteration 68, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:16] {2505} INFO -  at 104.9s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:16] {2311} INFO - iteration 69, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:37] {2505} INFO -  at 125.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:37] {2311} INFO - iteration 70, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:40] {2505} INFO -  at 129.2s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:40] {2311} INFO - iteration 71, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:50] {2505} INFO -  at 139.3s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:50] {2311} INFO - iteration 72, current learner xgboost\n",
            "[flaml.automl: 12-08 00:29:56] {2505} INFO -  at 144.8s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:29:56] {2311} INFO - iteration 73, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:02] {2505} INFO -  at 150.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:02] {2311} INFO - iteration 74, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:08] {2505} INFO -  at 157.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:08] {2311} INFO - iteration 75, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:15] {2505} INFO -  at 164.1s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:15] {2311} INFO - iteration 76, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:28] {2505} INFO -  at 177.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:28] {2311} INFO - iteration 77, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:32] {2505} INFO -  at 180.8s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:32] {2311} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:37] {2505} INFO -  at 185.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:37] {2311} INFO - iteration 79, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:46] {2505} INFO -  at 194.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:46] {2311} INFO - iteration 80, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:53] {2505} INFO -  at 201.6s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:53] {2311} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 12-08 00:30:59] {2505} INFO -  at 208.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:30:59] {2311} INFO - iteration 82, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:05] {2505} INFO -  at 214.2s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:05] {2311} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:13] {2505} INFO -  at 221.6s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:13] {2311} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:21] {2505} INFO -  at 230.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:21] {2311} INFO - iteration 85, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:27] {2505} INFO -  at 236.4s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:27] {2311} INFO - iteration 86, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:45] {2505} INFO -  at 254.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:45] {2311} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 12-08 00:31:57] {2505} INFO -  at 266.3s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:31:57] {2311} INFO - iteration 88, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:01] {2505} INFO -  at 269.5s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:01] {2311} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:07] {2505} INFO -  at 275.6s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:07] {2311} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:11] {2505} INFO -  at 280.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:11] {2311} INFO - iteration 91, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:23] {2505} INFO -  at 291.8s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:23] {2311} INFO - iteration 92, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:27] {2505} INFO -  at 296.4s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:27] {2311} INFO - iteration 93, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:35] {2505} INFO -  at 303.6s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:35] {2311} INFO - iteration 94, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:44] {2505} INFO -  at 313.2s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:44] {2311} INFO - iteration 95, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:52] {2505} INFO -  at 321.0s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:52] {2311} INFO - iteration 96, current learner xgboost\n",
            "[flaml.automl: 12-08 00:32:56] {2505} INFO -  at 324.9s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:32:56] {2311} INFO - iteration 97, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:01] {2505} INFO -  at 330.3s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:01] {2311} INFO - iteration 98, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:10] {2505} INFO -  at 338.5s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:10] {2311} INFO - iteration 99, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:19] {2505} INFO -  at 347.6s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:19] {2311} INFO - iteration 100, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:21] {2505} INFO -  at 350.2s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:21] {2311} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:32] {2505} INFO -  at 360.5s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:32] {2311} INFO - iteration 102, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:34] {2505} INFO -  at 363.2s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:34] {2311} INFO - iteration 103, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:39] {2505} INFO -  at 367.9s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:39] {2311} INFO - iteration 104, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:45] {2505} INFO -  at 373.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:45] {2311} INFO - iteration 105, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:47] {2505} INFO -  at 376.4s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:47] {2311} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 12-08 00:33:56] {2505} INFO -  at 384.7s,\testimator xgboost's best error=0.0072,\tbest estimator xgboost's best error=0.0072\n",
            "[flaml.automl: 12-08 00:33:56] {2311} INFO - iteration 107, current learner xgboost\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd12546-b8d1-40e2-e673-b431b93b8a3c",
        "id": "VZJwJ49LcI53"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "#paste retrained model\n",
        "sugg_reg_close_param = XGBRegressor(colsample_bylevel=0.9592879588141041, colsample_bytree=1.0,\n",
        "             grow_policy='lossguide', learning_rate=0.013488593217061895,\n",
        "             max_depth=0, max_leaves=5, min_child_weight=0.43462849479807825,\n",
        "             n_estimators=1038, n_jobs=-1, reg_alpha=0.02182073928249339,\n",
        "             reg_lambda=0.36764156052221886, subsample=0.9211577277604256,\n",
        "             tree_method='hist', use_label_encoder=False, verbosity=0)\n",
        "#paste finished\n",
        "sugg_reg_close_param.fit(X_train,y_train)\n",
        "y_pred_l=sugg_reg_close_param.predict(last_row)\n",
        "y_pred_l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.1232481], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviE4TesViu5"
      },
      "source": [
        "#for close prediction\n",
        "y_pred = sugg_reg_close_param.predict(X_test)\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N5zeqU0Viu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacbe9ca-0fbd-431e-a421-53df3f4da317"
      },
      "source": [
        "#for close regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) \n",
        "#print('MdAPE', metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.004857444772783917\n",
            "MSE: 4.0246388605608623e-05\n",
            "RMSE: 0.0063440041460901195\n",
            "MAPE: 6.68317053335399\n",
            "MedAE 0.003820765228271461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6tqvMO4EBCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4b153d-57cf-49c6-ca66-f7fb0adcbe99"
      },
      "source": [
        "print('Today the predictions are:')\n",
        "print('high', y_pred_h)\n",
        "print('close', y_pred_c)\n",
        "print('low', y_pred_l)\n",
        "print('Please use these as polarities.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today the predictions are:\n",
            "high [1.1309729]\n",
            "close [1.1257324]\n",
            "low [1.1235718]\n",
            "Please use these as polarities.\n"
          ]
        }
      ]
    }
  ]
}