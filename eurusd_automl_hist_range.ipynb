{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eurusd_automl_hist_range.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNc3t7fkLI0DLttPfMd0nSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gomlfx/ApiaryFund/blob/master/eurusd_automl_hist_range.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRBR17XyPDFl",
        "outputId": "f69ac61b-a04a-4d67-c680-3b56ba72132c"
      },
      "source": [
        "!pip install flaml"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.1.5)\n",
            "Requirement already satisfied: xgboost<=1.3.3,>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml) (0.90)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.4.1)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml) (3.3.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.0.1)\n",
            "Requirement already satisfied: NumPy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from flaml) (1.19.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml) (0.37.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L33tTbkVyHeD"
      },
      "source": [
        "#designed for Jupyter/kaggle/colab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import matplotlib for plotting \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#import normalization\n",
        "from sklearn import preprocessing\n",
        "import xgboost as xg\n",
        "from sklearn.ensemble import RandomForestRegressor as rf\n",
        "#import auto hyperparameter tuning\n",
        "from flaml import AutoML\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from lightgbm import LGBMRegressor\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cv2oYmBSAHBp"
      },
      "source": [
        " #MT4 csv \n",
        "df1=pd.read_csv('EURUSD1440.csv', names=['d','t','eu_o','eu_h','eu_l','eu_c','eu_v'])\n",
        "df_m_5 = df1.tail(2000)\n",
        "df2 = df1.tail(2000)\n",
        "# df2=pd.read_csv('GBPUSD1440.csv', names=['d','t','gu_o','gu_h','gu_l','gu_c','gu_v'])\n",
        "# df2 = df2.tail(2000)\n",
        "\n",
        "# df3=pd.read_csv('USDCAD1440.csv', names=['d','t','uc_o','uc_h','uc_l','uc_c','uc_v'])\n",
        "# df3 = df3.tail(2000)\n",
        "\n",
        "# df4=pd.read_csv('USDCHF1440.csv', names=['d','t','uf_o','uf_h','uf_l','uf_c','uf_v'])\n",
        "# df4 = df4.tail(2000)\n",
        "\n",
        "# df5=pd.read_csv('USDJPY1440.csv', names=['d','t','uj_o','uj_h','uj_l','uj_c','uj_v'])\n",
        "# df5 = df5.tail(2000)\n",
        "\n",
        "# df6=pd.read_csv('USDSEK1440.csv', names=['d','t','us_o','us_h','us_l','us_c','us_v'])\n",
        "# df6 = df6.tail(2000)\n",
        "\n",
        "# #using merge\n",
        "# df_m_1 = df1.merge(df2, on='d')\n",
        "# df_m_2 = df_m_1.merge(df3, on='d')\n",
        "# df_m_3 = df_m_2.merge(df4, on='d')\n",
        "# df_m_4 = df_m_3.merge(df5, on='d')\n",
        "# df_m_5 = df_m_4.merge(df6, on='d')\n",
        "# df_m_5 = df_m_5.drop(columns='t_x')\n",
        "# df_m_5 = df_m_5.drop(columns='t_y')\n",
        "\n",
        "# pd.set_option('display.max_columns', None)\n",
        "# print(df_m_5) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "U81LNdjsXdMk",
        "outputId": "0aea19b9-2f2b-479a-84e9-53fcfa285691"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>t</th>\n",
              "      <th>eu_o</th>\n",
              "      <th>eu_h</th>\n",
              "      <th>eu_l</th>\n",
              "      <th>eu_c</th>\n",
              "      <th>eu_v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12785</th>\n",
              "      <td>2021.12.07</td>\n",
              "      <td>00:00</td>\n",
              "      <td>1.12821</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>78783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12786</th>\n",
              "      <td>2021.12.08</td>\n",
              "      <td>00:00</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>85355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12787</th>\n",
              "      <td>2021.12.09</td>\n",
              "      <td>00:00</td>\n",
              "      <td>1.13422</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "      <td>71564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12788</th>\n",
              "      <td>2021.12.10</td>\n",
              "      <td>00:00</td>\n",
              "      <td>1.12913</td>\n",
              "      <td>1.13239</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13165</td>\n",
              "      <td>76961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12789</th>\n",
              "      <td>2021.12.13</td>\n",
              "      <td>00:00</td>\n",
              "      <td>1.13106</td>\n",
              "      <td>1.13191</td>\n",
              "      <td>1.12920</td>\n",
              "      <td>1.12960</td>\n",
              "      <td>7970</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                d      t     eu_o     eu_h     eu_l     eu_c   eu_v\n",
              "12785  2021.12.07  00:00  1.12821  1.12982  1.12273  1.12681  78783\n",
              "12786  2021.12.08  00:00  1.12650  1.13547  1.12627  1.13418  85355\n",
              "12787  2021.12.09  00:00  1.13422  1.13452  1.12782  1.12924  71564\n",
              "12788  2021.12.10  00:00  1.12913  1.13239  1.12650  1.13165  76961\n",
              "12789  2021.12.13  00:00  1.13106  1.13191  1.12920  1.12960   7970"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# #2 days forward\n",
        "# df_m_5['eu_High_next_day2'] = df_m_5['eu_h'].shift(-2)\n",
        "# df_m_5['eu_Low_next_day2'] = df_m_5['eu_l'].shift(-2)\n",
        "# df_m_5['eu_Close_next_day2'] = df_m_5['eu_c'].shift(-2) \n",
        "# #3 days forward\n",
        "# df_m_5['eu_High_next_day3'] = df_m_5['eu_h'].shift(-3)\n",
        "# df_m_5['eu_Low_next_day3'] = df_m_5['eu_l'].shift(-3)\n",
        "# df_m_5['eu_Close_next_day3'] = df_m_5['eu_c'].shift(-3) \n",
        "# #4 days forward \n",
        "# df_m_5['eu_High_next_day4'] = df_m_5['eu_h'].shift(-4)\n",
        "# df_m_5['eu_Low_next_day4'] = df_m_5['eu_l'].shift(-4)\n",
        "# df_m_5['eu_Close_next_day4'] = df_m_5['eu_c'].shift(-4) \n",
        "# #5 days forward\n",
        "# df_m_5['eu_High_next_day5'] = df_m_5['eu_h'].shift(-5)\n",
        "# df_m_5['eu_Low_next_day5'] = df_m_5['eu_l'].shift(-5)\n",
        "# df_m_5['eu_Close_next_day5'] = df_m_5['eu_c'].shift(-5) \n",
        "\n",
        "#Features\n",
        "#1 day ago (features)\n",
        "df_m_5['eu_High_last_day1'] = df_m_5['eu_h'].shift(1)\n",
        "df_m_5['eu_Low_last_day1'] = df_m_5['eu_l'].shift(1)\n",
        "df_m_5['eu_Close_last_day1'] = df_m_5['eu_c'].shift(1) \n",
        "#2 days ago\n",
        "df_m_5['eu_High_last_day2'] = df_m_5['eu_h'].shift(2)\n",
        "df_m_5['eu_Low_last_day2'] = df_m_5['eu_l'].shift(2)\n",
        "df_m_5['eu_Close_last_day2'] = df_m_5['eu_c'].shift(2) \n",
        "#3 days ago\n",
        "df_m_5['eu_High_last_day3'] = df_m_5['eu_h'].shift(3)\n",
        "df_m_5['eu_Low_last_day3'] = df_m_5['eu_l'].shift(3)\n",
        "df_m_5['eu_Close_last_day3'] = df_m_5['eu_c'].shift(3) \n",
        "#4 days ago \n",
        "df_m_5['eu_High_last_day4'] = df_m_5['eu_h'].shift(4)\n",
        "df_m_5['eu_Low_last_day4'] = df_m_5['eu_l'].shift(4)\n",
        "df_m_5['eu_Close_last_day4'] = df_m_5['eu_c'].shift(4) \n",
        "#5 days ago\n",
        "df_m_5['eu_High_last_day5'] = df_m_5['eu_h'].shift(5)\n",
        "df_m_5['eu_Low_last_day5'] = df_m_5['eu_l'].shift(5)\n",
        "df_m_5['eu_Close_last_day5'] = df_m_5['eu_c'].shift(5) \n",
        "#1 day ago (features)\n",
        "df_m_5['eu_High_last_day6'] = df_m_5['eu_h'].shift(6)\n",
        "df_m_5['eu_Low_last_day6'] = df_m_5['eu_l'].shift(6)\n",
        "df_m_5['eu_Close_last_day6'] = df_m_5['eu_c'].shift(6) \n",
        "#2 days ago\n",
        "df_m_5['eu_High_last_day7'] = df_m_5['eu_h'].shift(7)\n",
        "df_m_5['eu_Low_last_day7'] = df_m_5['eu_l'].shift(7)\n",
        "df_m_5['eu_Close_last_day7'] = df_m_5['eu_c'].shift(7) \n",
        "#3 days ago\n",
        "df_m_5['eu_High_last_day8'] = df_m_5['eu_h'].shift(8)\n",
        "df_m_5['eu_Low_last_day8'] = df_m_5['eu_l'].shift(8)\n",
        "df_m_5['eu_Close_last_day8'] = df_m_5['eu_c'].shift(8) \n",
        "#4 days ago \n",
        "df_m_5['eu_High_last_day9'] = df_m_5['eu_h'].shift(9)\n",
        "df_m_5['eu_Low_last_day9'] = df_m_5['eu_l'].shift(9)\n",
        "df_m_5['eu_Close_last_day9'] = df_m_5['eu_c'].shift(9) \n",
        "#5 days ago\n",
        "df_m_5['eu_High_last_day10'] = df_m_5['eu_h'].shift(10)\n",
        "df_m_5['eu_Low_last_day10'] = df_m_5['eu_l'].shift(10)\n",
        "df_m_5['eu_Close_last_day10'] = df_m_5['eu_c'].shift(10) \n",
        "\n",
        "#Target\n",
        "#1 day forward \n",
        "df_m_5['eu_High_next_day1'] = df_m_5['eu_h'].shift(-1)\n",
        "df_m_5['eu_Low_next_day1'] = df_m_5['eu_l'].shift(-1)\n",
        "df_m_5['eu_Close_next_day1'] = df_m_5['eu_c'].shift(-1) \n",
        "\n",
        "#drop null and useless columns\n",
        "df_m_5 = df_m_5.dropna()\n",
        "df_m_5 = df_m_5.drop(['t','eu_v'], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNLytMbSTCbH",
        "outputId": "5f63d7d0-4fd0-43c8-c6f0-cb59ee145999"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "wv_Xq-NlXzui",
        "outputId": "638f9200-9e03-4581-d5c2-72bb748728ee"
      },
      "source": [
        "df_m_5 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>eu_o</th>\n",
              "      <th>eu_h</th>\n",
              "      <th>eu_l</th>\n",
              "      <th>eu_c</th>\n",
              "      <th>eu_High_last_day1</th>\n",
              "      <th>eu_Low_last_day1</th>\n",
              "      <th>eu_Close_last_day1</th>\n",
              "      <th>eu_High_last_day2</th>\n",
              "      <th>eu_Low_last_day2</th>\n",
              "      <th>eu_Close_last_day2</th>\n",
              "      <th>eu_High_last_day3</th>\n",
              "      <th>eu_Low_last_day3</th>\n",
              "      <th>eu_Close_last_day3</th>\n",
              "      <th>eu_High_last_day4</th>\n",
              "      <th>eu_Low_last_day4</th>\n",
              "      <th>eu_Close_last_day4</th>\n",
              "      <th>eu_High_last_day5</th>\n",
              "      <th>eu_Low_last_day5</th>\n",
              "      <th>eu_Close_last_day5</th>\n",
              "      <th>eu_High_last_day6</th>\n",
              "      <th>eu_Low_last_day6</th>\n",
              "      <th>eu_Close_last_day6</th>\n",
              "      <th>eu_High_last_day7</th>\n",
              "      <th>eu_Low_last_day7</th>\n",
              "      <th>eu_Close_last_day7</th>\n",
              "      <th>eu_High_last_day8</th>\n",
              "      <th>eu_Low_last_day8</th>\n",
              "      <th>eu_Close_last_day8</th>\n",
              "      <th>eu_High_last_day9</th>\n",
              "      <th>eu_Low_last_day9</th>\n",
              "      <th>eu_Close_last_day9</th>\n",
              "      <th>eu_High_last_day10</th>\n",
              "      <th>eu_Low_last_day10</th>\n",
              "      <th>eu_Close_last_day10</th>\n",
              "      <th>eu_High_next_day1</th>\n",
              "      <th>eu_Low_next_day1</th>\n",
              "      <th>eu_Close_next_day1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10800</th>\n",
              "      <td>2014.04.11</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.39057</td>\n",
              "      <td>1.38632</td>\n",
              "      <td>1.38844</td>\n",
              "      <td>1.38988</td>\n",
              "      <td>1.38357</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.38620</td>\n",
              "      <td>1.37799</td>\n",
              "      <td>1.38536</td>\n",
              "      <td>1.38116</td>\n",
              "      <td>1.37371</td>\n",
              "      <td>1.37946</td>\n",
              "      <td>1.37483</td>\n",
              "      <td>1.36960</td>\n",
              "      <td>1.37412</td>\n",
              "      <td>1.37312</td>\n",
              "      <td>1.36725</td>\n",
              "      <td>1.37014</td>\n",
              "      <td>1.38066</td>\n",
              "      <td>1.36980</td>\n",
              "      <td>1.37168</td>\n",
              "      <td>1.38201</td>\n",
              "      <td>1.37530</td>\n",
              "      <td>1.37651</td>\n",
              "      <td>1.38152</td>\n",
              "      <td>1.37690</td>\n",
              "      <td>1.37932</td>\n",
              "      <td>1.38085</td>\n",
              "      <td>1.37215</td>\n",
              "      <td>1.37735</td>\n",
              "      <td>1.37729</td>\n",
              "      <td>1.37047</td>\n",
              "      <td>1.37513</td>\n",
              "      <td>1.38627</td>\n",
              "      <td>1.38080</td>\n",
              "      <td>1.38181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10801</th>\n",
              "      <td>2014.04.14</td>\n",
              "      <td>1.38573</td>\n",
              "      <td>1.38627</td>\n",
              "      <td>1.38080</td>\n",
              "      <td>1.38181</td>\n",
              "      <td>1.39057</td>\n",
              "      <td>1.38632</td>\n",
              "      <td>1.38844</td>\n",
              "      <td>1.38988</td>\n",
              "      <td>1.38357</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.38620</td>\n",
              "      <td>1.37799</td>\n",
              "      <td>1.38536</td>\n",
              "      <td>1.38116</td>\n",
              "      <td>1.37371</td>\n",
              "      <td>1.37946</td>\n",
              "      <td>1.37483</td>\n",
              "      <td>1.36960</td>\n",
              "      <td>1.37412</td>\n",
              "      <td>1.37312</td>\n",
              "      <td>1.36725</td>\n",
              "      <td>1.37014</td>\n",
              "      <td>1.38066</td>\n",
              "      <td>1.36980</td>\n",
              "      <td>1.37168</td>\n",
              "      <td>1.38201</td>\n",
              "      <td>1.37530</td>\n",
              "      <td>1.37651</td>\n",
              "      <td>1.38152</td>\n",
              "      <td>1.37690</td>\n",
              "      <td>1.37932</td>\n",
              "      <td>1.38085</td>\n",
              "      <td>1.37215</td>\n",
              "      <td>1.37735</td>\n",
              "      <td>1.38332</td>\n",
              "      <td>1.37899</td>\n",
              "      <td>1.38133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10802</th>\n",
              "      <td>2014.04.15</td>\n",
              "      <td>1.38185</td>\n",
              "      <td>1.38332</td>\n",
              "      <td>1.37899</td>\n",
              "      <td>1.38133</td>\n",
              "      <td>1.38627</td>\n",
              "      <td>1.38080</td>\n",
              "      <td>1.38181</td>\n",
              "      <td>1.39057</td>\n",
              "      <td>1.38632</td>\n",
              "      <td>1.38844</td>\n",
              "      <td>1.38988</td>\n",
              "      <td>1.38357</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.38620</td>\n",
              "      <td>1.37799</td>\n",
              "      <td>1.38536</td>\n",
              "      <td>1.38116</td>\n",
              "      <td>1.37371</td>\n",
              "      <td>1.37946</td>\n",
              "      <td>1.37483</td>\n",
              "      <td>1.36960</td>\n",
              "      <td>1.37412</td>\n",
              "      <td>1.37312</td>\n",
              "      <td>1.36725</td>\n",
              "      <td>1.37014</td>\n",
              "      <td>1.38066</td>\n",
              "      <td>1.36980</td>\n",
              "      <td>1.37168</td>\n",
              "      <td>1.38201</td>\n",
              "      <td>1.37530</td>\n",
              "      <td>1.37651</td>\n",
              "      <td>1.38152</td>\n",
              "      <td>1.37690</td>\n",
              "      <td>1.37932</td>\n",
              "      <td>1.38507</td>\n",
              "      <td>1.38035</td>\n",
              "      <td>1.38160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10803</th>\n",
              "      <td>2014.04.16</td>\n",
              "      <td>1.38133</td>\n",
              "      <td>1.38507</td>\n",
              "      <td>1.38035</td>\n",
              "      <td>1.38160</td>\n",
              "      <td>1.38332</td>\n",
              "      <td>1.37899</td>\n",
              "      <td>1.38133</td>\n",
              "      <td>1.38627</td>\n",
              "      <td>1.38080</td>\n",
              "      <td>1.38181</td>\n",
              "      <td>1.39057</td>\n",
              "      <td>1.38632</td>\n",
              "      <td>1.38844</td>\n",
              "      <td>1.38988</td>\n",
              "      <td>1.38357</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.38620</td>\n",
              "      <td>1.37799</td>\n",
              "      <td>1.38536</td>\n",
              "      <td>1.38116</td>\n",
              "      <td>1.37371</td>\n",
              "      <td>1.37946</td>\n",
              "      <td>1.37483</td>\n",
              "      <td>1.36960</td>\n",
              "      <td>1.37412</td>\n",
              "      <td>1.37312</td>\n",
              "      <td>1.36725</td>\n",
              "      <td>1.37014</td>\n",
              "      <td>1.38066</td>\n",
              "      <td>1.36980</td>\n",
              "      <td>1.37168</td>\n",
              "      <td>1.38201</td>\n",
              "      <td>1.37530</td>\n",
              "      <td>1.37651</td>\n",
              "      <td>1.38645</td>\n",
              "      <td>1.38109</td>\n",
              "      <td>1.38131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10804</th>\n",
              "      <td>2014.04.17</td>\n",
              "      <td>1.38160</td>\n",
              "      <td>1.38645</td>\n",
              "      <td>1.38109</td>\n",
              "      <td>1.38131</td>\n",
              "      <td>1.38507</td>\n",
              "      <td>1.38035</td>\n",
              "      <td>1.38160</td>\n",
              "      <td>1.38332</td>\n",
              "      <td>1.37899</td>\n",
              "      <td>1.38133</td>\n",
              "      <td>1.38627</td>\n",
              "      <td>1.38080</td>\n",
              "      <td>1.38181</td>\n",
              "      <td>1.39057</td>\n",
              "      <td>1.38632</td>\n",
              "      <td>1.38844</td>\n",
              "      <td>1.38988</td>\n",
              "      <td>1.38357</td>\n",
              "      <td>1.38868</td>\n",
              "      <td>1.38620</td>\n",
              "      <td>1.37799</td>\n",
              "      <td>1.38536</td>\n",
              "      <td>1.38116</td>\n",
              "      <td>1.37371</td>\n",
              "      <td>1.37946</td>\n",
              "      <td>1.37483</td>\n",
              "      <td>1.36960</td>\n",
              "      <td>1.37412</td>\n",
              "      <td>1.37312</td>\n",
              "      <td>1.36725</td>\n",
              "      <td>1.37014</td>\n",
              "      <td>1.38066</td>\n",
              "      <td>1.36980</td>\n",
              "      <td>1.37168</td>\n",
              "      <td>1.38222</td>\n",
              "      <td>1.38068</td>\n",
              "      <td>1.38068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12784</th>\n",
              "      <td>2021.12.06</td>\n",
              "      <td>1.12997</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.12748</td>\n",
              "      <td>1.12258</td>\n",
              "      <td>1.12483</td>\n",
              "      <td>1.12903</td>\n",
              "      <td>1.12306</td>\n",
              "      <td>1.12333</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12785</th>\n",
              "      <td>2021.12.07</td>\n",
              "      <td>1.12821</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.12748</td>\n",
              "      <td>1.12258</td>\n",
              "      <td>1.12483</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12786</th>\n",
              "      <td>2021.12.08</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12787</th>\n",
              "      <td>2021.12.09</td>\n",
              "      <td>1.13422</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.13239</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12788</th>\n",
              "      <td>2021.12.10</td>\n",
              "      <td>1.12913</td>\n",
              "      <td>1.13239</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13165</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.13191</td>\n",
              "      <td>1.12920</td>\n",
              "      <td>1.12960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1989 rows × 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                d     eu_o  ...  eu_Low_next_day1  eu_Close_next_day1\n",
              "10800  2014.04.11  1.38868  ...           1.38080             1.38181\n",
              "10801  2014.04.14  1.38573  ...           1.37899             1.38133\n",
              "10802  2014.04.15  1.38185  ...           1.38035             1.38160\n",
              "10803  2014.04.16  1.38133  ...           1.38109             1.38131\n",
              "10804  2014.04.17  1.38160  ...           1.38068             1.38068\n",
              "...           ...      ...  ...               ...                 ...\n",
              "12784  2021.12.06  1.12997  ...           1.12273             1.12681\n",
              "12785  2021.12.07  1.12821  ...           1.12627             1.13418\n",
              "12786  2021.12.08  1.12650  ...           1.12782             1.12924\n",
              "12787  2021.12.09  1.13422  ...           1.12650             1.13165\n",
              "12788  2021.12.10  1.12913  ...           1.12920             1.12960\n",
              "\n",
              "[1989 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXIM5S0O1UHY"
      },
      "source": [
        "df_m_5.insert(1,'index',df_m_5.index)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MT4vPMgBZrg8"
      },
      "source": [
        "# #new column: high vs low\n",
        "# df_m_5['eu_h_or_l'] = ((df_m_5.eu_h - df_m_5.eu_o) > (df_m_5.eu_o - df_m_5.eu_l)) \n",
        "# df_m_5.eu_h_or_l = df_m_5.eu_h_or_l.replace({True:1,False:0})\n",
        "\n",
        "# #new column: close vs yesterday\n",
        "# df_m_5['eu_c_vs_c'] = (df_m_5.eu_c > df_m_5.eu_o) \n",
        "# df_m_5.eu_c_vs_c = df_m_5.eu_c_vs_c.replace({True:1,False:0})\n",
        "\n",
        "# #new column: shift tomorrow to today\n",
        "# df_m_5['eu_High_next_day'] = df_m_5['eu_h'].shift(-1)\n",
        "# df_m_5['eu_Low_next_day'] = df_m_5['eu_l'].shift(-1)\n",
        "# df_m_5['eu_Close_next_day'] = df_m_5['eu_c'].shift(-1)\n",
        "# df_m_5 = df_m_5.dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "sbaNPw8ctli1",
        "outputId": "783ac7e2-56f9-418e-c7f2-fcd6ad26059f"
      },
      "source": [
        "df_m_5.tail()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>d</th>\n",
              "      <th>index</th>\n",
              "      <th>eu_o</th>\n",
              "      <th>eu_h</th>\n",
              "      <th>eu_l</th>\n",
              "      <th>eu_c</th>\n",
              "      <th>eu_High_last_day1</th>\n",
              "      <th>eu_Low_last_day1</th>\n",
              "      <th>eu_Close_last_day1</th>\n",
              "      <th>eu_High_last_day2</th>\n",
              "      <th>eu_Low_last_day2</th>\n",
              "      <th>eu_Close_last_day2</th>\n",
              "      <th>eu_High_last_day3</th>\n",
              "      <th>eu_Low_last_day3</th>\n",
              "      <th>eu_Close_last_day3</th>\n",
              "      <th>eu_High_last_day4</th>\n",
              "      <th>eu_Low_last_day4</th>\n",
              "      <th>eu_Close_last_day4</th>\n",
              "      <th>eu_High_last_day5</th>\n",
              "      <th>eu_Low_last_day5</th>\n",
              "      <th>eu_Close_last_day5</th>\n",
              "      <th>eu_High_last_day6</th>\n",
              "      <th>eu_Low_last_day6</th>\n",
              "      <th>eu_Close_last_day6</th>\n",
              "      <th>eu_High_last_day7</th>\n",
              "      <th>eu_Low_last_day7</th>\n",
              "      <th>eu_Close_last_day7</th>\n",
              "      <th>eu_High_last_day8</th>\n",
              "      <th>eu_Low_last_day8</th>\n",
              "      <th>eu_Close_last_day8</th>\n",
              "      <th>eu_High_last_day9</th>\n",
              "      <th>eu_Low_last_day9</th>\n",
              "      <th>eu_Close_last_day9</th>\n",
              "      <th>eu_High_last_day10</th>\n",
              "      <th>eu_Low_last_day10</th>\n",
              "      <th>eu_Close_last_day10</th>\n",
              "      <th>eu_High_next_day1</th>\n",
              "      <th>eu_Low_next_day1</th>\n",
              "      <th>eu_Close_next_day1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12784</th>\n",
              "      <td>2021.12.06</td>\n",
              "      <td>12784</td>\n",
              "      <td>1.12997</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.12748</td>\n",
              "      <td>1.12258</td>\n",
              "      <td>1.12483</td>\n",
              "      <td>1.12903</td>\n",
              "      <td>1.12306</td>\n",
              "      <td>1.12333</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12785</th>\n",
              "      <td>2021.12.07</td>\n",
              "      <td>12785</td>\n",
              "      <td>1.12821</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.12748</td>\n",
              "      <td>1.12258</td>\n",
              "      <td>1.12483</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12786</th>\n",
              "      <td>2021.12.08</td>\n",
              "      <td>12786</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.12551</td>\n",
              "      <td>1.11859</td>\n",
              "      <td>1.12000</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12787</th>\n",
              "      <td>2021.12.09</td>\n",
              "      <td>12787</td>\n",
              "      <td>1.13422</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.12295</td>\n",
              "      <td>1.11959</td>\n",
              "      <td>1.12062</td>\n",
              "      <td>1.13239</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12788</th>\n",
              "      <td>2021.12.10</td>\n",
              "      <td>12788</td>\n",
              "      <td>1.12913</td>\n",
              "      <td>1.13239</td>\n",
              "      <td>1.12650</td>\n",
              "      <td>1.13165</td>\n",
              "      <td>1.13452</td>\n",
              "      <td>1.12782</td>\n",
              "      <td>1.12924</td>\n",
              "      <td>1.13547</td>\n",
              "      <td>1.12627</td>\n",
              "      <td>1.13418</td>\n",
              "      <td>1.12982</td>\n",
              "      <td>1.12273</td>\n",
              "      <td>1.12681</td>\n",
              "      <td>1.13109</td>\n",
              "      <td>1.12664</td>\n",
              "      <td>1.12848</td>\n",
              "      <td>1.13333</td>\n",
              "      <td>1.12665</td>\n",
              "      <td>1.13088</td>\n",
              "      <td>1.13475</td>\n",
              "      <td>1.12952</td>\n",
              "      <td>1.13013</td>\n",
              "      <td>1.13594</td>\n",
              "      <td>1.13023</td>\n",
              "      <td>1.13190</td>\n",
              "      <td>1.13827</td>\n",
              "      <td>1.12350</td>\n",
              "      <td>1.13390</td>\n",
              "      <td>1.13117</td>\n",
              "      <td>1.12582</td>\n",
              "      <td>1.12918</td>\n",
              "      <td>1.13295</td>\n",
              "      <td>1.12051</td>\n",
              "      <td>1.13177</td>\n",
              "      <td>1.13191</td>\n",
              "      <td>1.12920</td>\n",
              "      <td>1.12960</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                d  index  ...  eu_Low_next_day1  eu_Close_next_day1\n",
              "12784  2021.12.06  12784  ...           1.12273             1.12681\n",
              "12785  2021.12.07  12785  ...           1.12627             1.13418\n",
              "12786  2021.12.08  12786  ...           1.12782             1.12924\n",
              "12787  2021.12.09  12787  ...           1.12650             1.13165\n",
              "12788  2021.12.10  12788  ...           1.12920             1.12960\n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMLvjXAmBoSE",
        "outputId": "309a7210-d137-4d22-9b31-67f0af64a4ab"
      },
      "source": [
        "\n",
        "df_m_5.isna().sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "d                      0\n",
              "index                  0\n",
              "eu_o                   0\n",
              "eu_h                   0\n",
              "eu_l                   0\n",
              "eu_c                   0\n",
              "eu_High_last_day1      0\n",
              "eu_Low_last_day1       0\n",
              "eu_Close_last_day1     0\n",
              "eu_High_last_day2      0\n",
              "eu_Low_last_day2       0\n",
              "eu_Close_last_day2     0\n",
              "eu_High_last_day3      0\n",
              "eu_Low_last_day3       0\n",
              "eu_Close_last_day3     0\n",
              "eu_High_last_day4      0\n",
              "eu_Low_last_day4       0\n",
              "eu_Close_last_day4     0\n",
              "eu_High_last_day5      0\n",
              "eu_Low_last_day5       0\n",
              "eu_Close_last_day5     0\n",
              "eu_High_last_day6      0\n",
              "eu_Low_last_day6       0\n",
              "eu_Close_last_day6     0\n",
              "eu_High_last_day7      0\n",
              "eu_Low_last_day7       0\n",
              "eu_Close_last_day7     0\n",
              "eu_High_last_day8      0\n",
              "eu_Low_last_day8       0\n",
              "eu_Close_last_day8     0\n",
              "eu_High_last_day9      0\n",
              "eu_Low_last_day9       0\n",
              "eu_Close_last_day9     0\n",
              "eu_High_last_day10     0\n",
              "eu_Low_last_day10      0\n",
              "eu_Close_last_day10    0\n",
              "eu_High_next_day1      0\n",
              "eu_Low_next_day1       0\n",
              "eu_Close_next_day1     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEAMxmGyCWRB",
        "outputId": "863018c8-2de9-488c-83bf-45242deba4d9"
      },
      "source": [
        "df_m_5.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1989 entries, 10800 to 12788\n",
            "Data columns (total 39 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   d                    1989 non-null   object \n",
            " 1   index                1989 non-null   int64  \n",
            " 2   eu_o                 1989 non-null   float64\n",
            " 3   eu_h                 1989 non-null   float64\n",
            " 4   eu_l                 1989 non-null   float64\n",
            " 5   eu_c                 1989 non-null   float64\n",
            " 6   eu_High_last_day1    1989 non-null   float64\n",
            " 7   eu_Low_last_day1     1989 non-null   float64\n",
            " 8   eu_Close_last_day1   1989 non-null   float64\n",
            " 9   eu_High_last_day2    1989 non-null   float64\n",
            " 10  eu_Low_last_day2     1989 non-null   float64\n",
            " 11  eu_Close_last_day2   1989 non-null   float64\n",
            " 12  eu_High_last_day3    1989 non-null   float64\n",
            " 13  eu_Low_last_day3     1989 non-null   float64\n",
            " 14  eu_Close_last_day3   1989 non-null   float64\n",
            " 15  eu_High_last_day4    1989 non-null   float64\n",
            " 16  eu_Low_last_day4     1989 non-null   float64\n",
            " 17  eu_Close_last_day4   1989 non-null   float64\n",
            " 18  eu_High_last_day5    1989 non-null   float64\n",
            " 19  eu_Low_last_day5     1989 non-null   float64\n",
            " 20  eu_Close_last_day5   1989 non-null   float64\n",
            " 21  eu_High_last_day6    1989 non-null   float64\n",
            " 22  eu_Low_last_day6     1989 non-null   float64\n",
            " 23  eu_Close_last_day6   1989 non-null   float64\n",
            " 24  eu_High_last_day7    1989 non-null   float64\n",
            " 25  eu_Low_last_day7     1989 non-null   float64\n",
            " 26  eu_Close_last_day7   1989 non-null   float64\n",
            " 27  eu_High_last_day8    1989 non-null   float64\n",
            " 28  eu_Low_last_day8     1989 non-null   float64\n",
            " 29  eu_Close_last_day8   1989 non-null   float64\n",
            " 30  eu_High_last_day9    1989 non-null   float64\n",
            " 31  eu_Low_last_day9     1989 non-null   float64\n",
            " 32  eu_Close_last_day9   1989 non-null   float64\n",
            " 33  eu_High_last_day10   1989 non-null   float64\n",
            " 34  eu_Low_last_day10    1989 non-null   float64\n",
            " 35  eu_Close_last_day10  1989 non-null   float64\n",
            " 36  eu_High_next_day1    1989 non-null   float64\n",
            " 37  eu_Low_next_day1     1989 non-null   float64\n",
            " 38  eu_Close_next_day1   1989 non-null   float64\n",
            "dtypes: float64(37), int64(1), object(1)\n",
            "memory usage: 621.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppP40BoAwFGk",
        "outputId": "85815a0a-0e09-424b-8dcc-3b24d6515fa8"
      },
      "source": [
        "#extract row for variable\n",
        "last_row = df_m_5.iloc[-1:,np.r_[2:36]].values\n",
        "print(last_row) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.12913 1.13239 1.1265  1.13165 1.13452 1.12782 1.12924 1.13547 1.12627\n",
            "  1.13418 1.12982 1.12273 1.12681 1.13109 1.12664 1.12848 1.13333 1.12665\n",
            "  1.13088 1.13475 1.12952 1.13013 1.13594 1.13023 1.1319  1.13827 1.1235\n",
            "  1.1339  1.13117 1.12582 1.12918 1.13295 1.12051 1.13177]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhfQ9UadZ1PE",
        "outputId": "ee9ec9ca-1a58-470e-bfda-1b941edc07f1"
      },
      "source": [
        "#for high prediction\n",
        "#select rows to use for x,y\n",
        "x_h = df_m_5.iloc[:,np.r_[2:36]].values\n",
        "print(x_h)\n",
        "y_h = df_m_5.iloc[:,[36]].values\n",
        "print(y_h) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.38868 1.39057 1.38632 ... 1.37729 1.37047 1.37513]\n",
            " [1.38573 1.38627 1.3808  ... 1.38085 1.37215 1.37735]\n",
            " [1.38185 1.38332 1.37899 ... 1.38152 1.3769  1.37932]\n",
            " ...\n",
            " [1.1265  1.13547 1.12627 ... 1.12551 1.11859 1.12   ]\n",
            " [1.13422 1.13452 1.12782 ... 1.12295 1.11959 1.12062]\n",
            " [1.12913 1.13239 1.1265  ... 1.13295 1.12051 1.13177]]\n",
            "[[1.38627]\n",
            " [1.38332]\n",
            " [1.38507]\n",
            " ...\n",
            " [1.13452]\n",
            " [1.13239]\n",
            " [1.13191]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqTW_s-u3g67"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_h, y_h, test_size = 0.30)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v4b3tpQtg8_",
        "outputId": "ec75b00c-2ffd-4143-a279-1cc49b59498f"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=\"auto\", task=\"regression\", time_budget=None, eval_method=\"auto\", n_jobs=-1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-13 05:11:35] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-13 05:11:35] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-13 05:11:35] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-13 05:11:35] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-13 05:11:35] {2071} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
            "[flaml.automl: 12-13 05:11:35] {2311} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:35] {2425} INFO - Estimated sufficient time budget=784s. Estimated necessary time budget=6s.\n",
            "[flaml.automl: 12-13 05:11:35] {2505} INFO -  at 0.1s,\testimator lgbm's best error=0.4813,\tbest estimator lgbm's best error=0.4813\n",
            "[flaml.automl: 12-13 05:11:35] {2311} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:35] {2505} INFO -  at 0.2s,\testimator lgbm's best error=0.4813,\tbest estimator lgbm's best error=0.4813\n",
            "[flaml.automl: 12-13 05:11:35] {2311} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:36] {2505} INFO -  at 0.3s,\testimator lgbm's best error=0.1263,\tbest estimator lgbm's best error=0.1263\n",
            "[flaml.automl: 12-13 05:11:36] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:36] {2505} INFO -  at 0.5s,\testimator xgboost's best error=41.1304,\tbest estimator lgbm's best error=0.1263\n",
            "[flaml.automl: 12-13 05:11:36] {2311} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:36] {2505} INFO -  at 0.6s,\testimator lgbm's best error=0.0116,\tbest estimator lgbm's best error=0.0116\n",
            "[flaml.automl: 12-13 05:11:36] {2311} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:36] {2505} INFO -  at 0.6s,\testimator lgbm's best error=0.0116,\tbest estimator lgbm's best error=0.0116\n",
            "[flaml.automl: 12-13 05:11:36] {2311} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:36] {2505} INFO -  at 0.7s,\testimator lgbm's best error=0.0078,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:11:36] {2311} INFO - iteration 7, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:37] {2505} INFO -  at 1.9s,\testimator extra_tree's best error=0.0688,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:11:37] {2311} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:37] {2505} INFO -  at 2.0s,\testimator lgbm's best error=0.0078,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:11:37] {2311} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:37] {2505} INFO -  at 2.1s,\testimator lgbm's best error=0.0078,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:11:37] {2311} INFO - iteration 10, current learner rf\n",
            "[flaml.automl: 12-13 05:11:38] {2505} INFO -  at 3.2s,\testimator rf's best error=0.0617,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:11:38] {2311} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:39] {2505} INFO -  at 3.3s,\testimator lgbm's best error=0.0066,\tbest estimator lgbm's best error=0.0066\n",
            "[flaml.automl: 12-13 05:11:39] {2311} INFO - iteration 12, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:39] {2505} INFO -  at 3.4s,\testimator lgbm's best error=0.0066,\tbest estimator lgbm's best error=0.0066\n",
            "[flaml.automl: 12-13 05:11:39] {2311} INFO - iteration 13, current learner rf\n",
            "[flaml.automl: 12-13 05:11:40] {2505} INFO -  at 4.8s,\testimator rf's best error=0.0110,\tbest estimator lgbm's best error=0.0066\n",
            "[flaml.automl: 12-13 05:11:40] {2311} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:40] {2505} INFO -  at 5.1s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:40] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:40] {2505} INFO -  at 5.2s,\testimator xgboost's best error=41.1304,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:40] {2311} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:41] {2505} INFO -  at 5.8s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:41] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:41] {2505} INFO -  at 5.9s,\testimator xgboost's best error=8.6814,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:41] {2311} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:41] {2505} INFO -  at 6.1s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:41] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:41] {2505} INFO -  at 6.2s,\testimator xgboost's best error=0.0268,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:41] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:42] {2505} INFO -  at 6.3s,\testimator xgboost's best error=0.0268,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:42] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:42] {2505} INFO -  at 6.4s,\testimator xgboost's best error=0.0268,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:42] {2311} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:42] {2505} INFO -  at 6.7s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:42] {2311} INFO - iteration 23, current learner rf\n",
            "[flaml.automl: 12-13 05:11:43] {2505} INFO -  at 7.9s,\testimator rf's best error=0.0110,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:43] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:43] {2505} INFO -  at 8.1s,\testimator xgboost's best error=0.0110,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:43] {2311} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:45] {2505} INFO -  at 9.2s,\testimator extra_tree's best error=0.0136,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:45] {2311} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:45] {2505} INFO -  at 9.4s,\testimator xgboost's best error=0.0110,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:45] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:45] {2505} INFO -  at 9.5s,\testimator xgboost's best error=0.0110,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:45] {2311} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:46] {2505} INFO -  at 10.7s,\testimator extra_tree's best error=0.0136,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:46] {2311} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:47] {2505} INFO -  at 12.0s,\testimator extra_tree's best error=0.0063,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:47] {2311} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:47] {2505} INFO -  at 12.2s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:47] {2311} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:48] {2505} INFO -  at 12.9s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:48] {2311} INFO - iteration 32, current learner rf\n",
            "[flaml.automl: 12-13 05:11:50] {2505} INFO -  at 14.3s,\testimator rf's best error=0.0042,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:50] {2311} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:51] {2505} INFO -  at 15.8s,\testimator extra_tree's best error=0.0047,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:51] {2311} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:51] {2505} INFO -  at 16.0s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:51] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:52] {2505} INFO -  at 16.2s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:52] {2311} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:53] {2505} INFO -  at 17.5s,\testimator extra_tree's best error=0.0047,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:53] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:53] {2505} INFO -  at 17.6s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:53] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:53] {2505} INFO -  at 17.8s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:53] {2311} INFO - iteration 39, current learner rf\n",
            "[flaml.automl: 12-13 05:11:55] {2505} INFO -  at 19.2s,\testimator rf's best error=0.0040,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:55] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:55] {2505} INFO -  at 19.5s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:55] {2311} INFO - iteration 41, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:56] {2505} INFO -  at 20.7s,\testimator extra_tree's best error=0.0042,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:56] {2311} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:57] {2505} INFO -  at 21.4s,\testimator lgbm's best error=0.0039,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:57] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:57] {2505} INFO -  at 21.6s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:57] {2311} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:11:58] {2505} INFO -  at 23.0s,\testimator extra_tree's best error=0.0042,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:58] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-13 05:11:59] {2505} INFO -  at 23.3s,\testimator xgboost's best error=0.0083,\tbest estimator lgbm's best error=0.0039\n",
            "[flaml.automl: 12-13 05:11:59] {2311} INFO - iteration 46, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:59] {2505} INFO -  at 23.6s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:11:59] {2311} INFO - iteration 47, current learner lgbm\n",
            "[flaml.automl: 12-13 05:11:59] {2505} INFO -  at 23.8s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:11:59] {2311} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:00] {2505} INFO -  at 24.3s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:00] {2311} INFO - iteration 49, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:00] {2505} INFO -  at 24.8s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:00] {2311} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:02] {2505} INFO -  at 26.3s,\testimator extra_tree's best error=0.0042,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:02] {2311} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:02] {2505} INFO -  at 26.5s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:02] {2311} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:02] {2505} INFO -  at 26.8s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:02] {2311} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:02] {2505} INFO -  at 27.2s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:02] {2311} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:03] {2505} INFO -  at 27.9s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:03] {2311} INFO - iteration 55, current learner rf\n",
            "[flaml.automl: 12-13 05:12:04] {2505} INFO -  at 29.1s,\testimator rf's best error=0.0040,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:04] {2311} INFO - iteration 56, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:05] {2505} INFO -  at 29.3s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:05] {2311} INFO - iteration 57, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:05] {2505} INFO -  at 29.8s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:05] {2311} INFO - iteration 58, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:05] {2505} INFO -  at 30.1s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:05] {2311} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:05] {2505} INFO -  at 30.2s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:05] {2311} INFO - iteration 60, current learner rf\n",
            "[flaml.automl: 12-13 05:12:07] {2505} INFO -  at 31.4s,\testimator rf's best error=0.0040,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:07] {2311} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:08] {2505} INFO -  at 32.4s,\testimator lgbm's best error=0.0038,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:08] {2311} INFO - iteration 62, current learner rf\n",
            "[flaml.automl: 12-13 05:12:09] {2505} INFO -  at 33.9s,\testimator rf's best error=0.0040,\tbest estimator lgbm's best error=0.0038\n",
            "[flaml.automl: 12-13 05:12:09] {2311} INFO - iteration 63, current learner rf\n",
            "[flaml.automl: 12-13 05:12:11] {2505} INFO -  at 35.6s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:11] {2311} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:11] {2505} INFO -  at 35.9s,\testimator xgb_limitdepth's best error=0.0881,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:11] {2311} INFO - iteration 65, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:12] {2505} INFO -  at 37.1s,\testimator extra_tree's best error=0.0042,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:12] {2311} INFO - iteration 66, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:13] {2505} INFO -  at 37.3s,\testimator xgb_limitdepth's best error=0.0881,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:13] {2311} INFO - iteration 67, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:13] {2505} INFO -  at 37.6s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:13] {2311} INFO - iteration 68, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:13] {2505} INFO -  at 37.9s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:13] {2311} INFO - iteration 69, current learner rf\n",
            "[flaml.automl: 12-13 05:12:14] {2505} INFO -  at 39.2s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:14] {2311} INFO - iteration 70, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:15] {2505} INFO -  at 39.4s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:15] {2311} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:15] {2505} INFO -  at 39.5s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:15] {2311} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:15] {2505} INFO -  at 40.1s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:15] {2311} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:16] {2505} INFO -  at 40.4s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:16] {2311} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:16] {2505} INFO -  at 40.6s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:16] {2311} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:16] {2505} INFO -  at 41.0s,\testimator xgb_limitdepth's best error=0.0058,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:16] {2311} INFO - iteration 76, current learner rf\n",
            "[flaml.automl: 12-13 05:12:18] {2505} INFO -  at 42.2s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:18] {2311} INFO - iteration 77, current learner rf\n",
            "[flaml.automl: 12-13 05:12:20] {2505} INFO -  at 44.5s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:20] {2311} INFO - iteration 78, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:12:20] {2505} INFO -  at 44.7s,\testimator xgb_limitdepth's best error=0.0057,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:20] {2311} INFO - iteration 79, current learner rf\n",
            "[flaml.automl: 12-13 05:12:21] {2505} INFO -  at 46.2s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:21] {2311} INFO - iteration 80, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:22] {2505} INFO -  at 46.4s,\testimator lgbm's best error=0.0038,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:22] {2311} INFO - iteration 81, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:23] {2505} INFO -  at 47.6s,\testimator extra_tree's best error=0.0042,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:23] {2311} INFO - iteration 82, current learner rf\n",
            "[flaml.automl: 12-13 05:12:25] {2505} INFO -  at 49.9s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:25] {2311} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:26] {2505} INFO -  at 51.2s,\testimator extra_tree's best error=0.0042,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:26] {2311} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:28] {2505} INFO -  at 52.4s,\testimator extra_tree's best error=0.0042,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:28] {2311} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:29] {2505} INFO -  at 53.7s,\testimator extra_tree's best error=0.0040,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:29] {2311} INFO - iteration 86, current learner rf\n",
            "[flaml.automl: 12-13 05:12:30] {2505} INFO -  at 55.0s,\testimator rf's best error=0.0037,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:30] {2311} INFO - iteration 87, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:12:32] {2505} INFO -  at 56.2s,\testimator extra_tree's best error=0.0040,\tbest estimator rf's best error=0.0037\n",
            "[flaml.automl: 12-13 05:12:32] {2311} INFO - iteration 88, current learner rf\n",
            "[flaml.automl: 12-13 05:12:35] {2505} INFO -  at 59.6s,\testimator rf's best error=0.0036,\tbest estimator rf's best error=0.0036\n",
            "[flaml.automl: 12-13 05:12:35] {2311} INFO - iteration 89, current learner lgbm\n",
            "[flaml.automl: 12-13 05:12:35] {2505} INFO -  at 60.0s,\testimator lgbm's best error=0.0038,\tbest estimator rf's best error=0.0036\n",
            "[flaml.automl: 12-13 05:12:36] {2717} INFO - retrain rf for 0.8s\n",
            "[flaml.automl: 12-13 05:12:36] {2722} INFO - retrained model: RandomForestRegressor(max_features=0.7153649632061108, max_leaf_nodes=252,\n",
            "                      n_estimators=47, n_jobs=-1)\n",
            "[flaml.automl: 12-13 05:12:36] {2100} INFO - fit succeeded\n",
            "[flaml.automl: 12-13 05:12:36] {2102} INFO - Time taken to find the best model: 59.57794523239136\n",
            "[flaml.automl: 12-13 05:12:36] {2116} WARNING - Time taken to find the best model is 99% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5yHztyhnm3x",
        "outputId": "9b49a862-5bc9-4bcf-b45c-894baec3fba5"
      },
      "source": [
        "#paste retrained model\n",
        "sugg_reg_high_param = RandomForestRegressor(max_features=0.7153649632061108, max_leaf_nodes=252,\n",
        "                      n_estimators=47, n_jobs=-1)\n",
        "#paste finished\n",
        "sugg_reg_high_param.fit(X_train,y_train)\n",
        "y_pred_h=sugg_reg_high_param.predict(last_row)\n",
        "y_pred_h"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.13363275])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmHBSVwEPp5t"
      },
      "source": [
        "y_pred = sugg_reg_high_param.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4bGcB9U62Js"
      },
      "source": [
        "def mean_absolute_percentage_error(y_true,y_pred):\n",
        "  y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suK5rCpV0p9g",
        "outputId": "2cdf5406-51f6-4efd-9791-db931250a593"
      },
      "source": [
        "#for regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.003000246367091531\n",
            "MSE: 1.921056714198677e-05\n",
            "RMSE: 0.004382986098767228\n",
            "MAPE: 6.22102559115412\n",
            "MedAE 0.002337077577859503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIHV30_ZH5eg",
        "outputId": "54f87c91-1bec-42f8-eeaa-e1992726c441"
      },
      "source": [
        "#for low prediction\n",
        "#select rows to use for x,y\n",
        "x_l = df_m_5.iloc[:,np.r_[2:36]].values\n",
        "print(x_l)\n",
        "y_l = df_m_5.iloc[:,[37]].values\n",
        "print(y_l) "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.38868 1.39057 1.38632 ... 1.37729 1.37047 1.37513]\n",
            " [1.38573 1.38627 1.3808  ... 1.38085 1.37215 1.37735]\n",
            " [1.38185 1.38332 1.37899 ... 1.38152 1.3769  1.37932]\n",
            " ...\n",
            " [1.1265  1.13547 1.12627 ... 1.12551 1.11859 1.12   ]\n",
            " [1.13422 1.13452 1.12782 ... 1.12295 1.11959 1.12062]\n",
            " [1.12913 1.13239 1.1265  ... 1.13295 1.12051 1.13177]]\n",
            "[[1.3808 ]\n",
            " [1.37899]\n",
            " [1.38035]\n",
            " ...\n",
            " [1.12782]\n",
            " [1.1265 ]\n",
            " [1.1292 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-d3TjyWS22Q"
      },
      "source": [
        "#for low prediction\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_l, y_l, test_size = 0.30)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6726e53a-f7fa-4d39-eca7-4ee1555f2aa3",
        "id": "9WTZr86wX-dR"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=\"auto\", task=\"regression\", time_budget=None, eval_method=\"auto\", n_jobs=-1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-13 05:15:36] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-13 05:15:36] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-13 05:15:36] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-13 05:15:36] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-13 05:15:36] {2071} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:36] {2425} INFO - Estimated sufficient time budget=741s. Estimated necessary time budget=5s.\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.1s,\testimator lgbm's best error=0.4815,\tbest estimator lgbm's best error=0.4815\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.2s,\testimator lgbm's best error=0.4815,\tbest estimator lgbm's best error=0.4815\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.2s,\testimator lgbm's best error=0.1266,\tbest estimator lgbm's best error=0.1266\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.3s,\testimator xgboost's best error=39.2682,\tbest estimator lgbm's best error=0.1266\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.5s,\testimator lgbm's best error=0.0126,\tbest estimator lgbm's best error=0.0126\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:36] {2505} INFO -  at 0.5s,\testimator lgbm's best error=0.0126,\tbest estimator lgbm's best error=0.0126\n",
            "[flaml.automl: 12-13 05:15:36] {2311} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:37] {2505} INFO -  at 0.6s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:15:37] {2311} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:37] {2505} INFO -  at 0.7s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:15:37] {2311} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:37] {2505} INFO -  at 0.8s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:15:37] {2311} INFO - iteration 9, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:38] {2505} INFO -  at 2.0s,\testimator extra_tree's best error=0.0593,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:15:38] {2311} INFO - iteration 10, current learner rf\n",
            "[flaml.automl: 12-13 05:15:39] {2505} INFO -  at 3.3s,\testimator rf's best error=0.0614,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:15:39] {2311} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:39] {2505} INFO -  at 3.4s,\testimator lgbm's best error=0.0071,\tbest estimator lgbm's best error=0.0071\n",
            "[flaml.automl: 12-13 05:15:39] {2311} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 12-13 05:15:40] {2505} INFO -  at 4.6s,\testimator rf's best error=0.0126,\tbest estimator lgbm's best error=0.0071\n",
            "[flaml.automl: 12-13 05:15:40] {2311} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:41] {2505} INFO -  at 4.6s,\testimator xgboost's best error=39.2682,\tbest estimator lgbm's best error=0.0071\n",
            "[flaml.automl: 12-13 05:15:41] {2311} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:41] {2505} INFO -  at 4.7s,\testimator lgbm's best error=0.0071,\tbest estimator lgbm's best error=0.0071\n",
            "[flaml.automl: 12-13 05:15:41] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:41] {2505} INFO -  at 4.8s,\testimator xgboost's best error=8.2908,\tbest estimator lgbm's best error=0.0071\n",
            "[flaml.automl: 12-13 05:15:41] {2311} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:41] {2505} INFO -  at 5.2s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:41] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:41] {2505} INFO -  at 5.3s,\testimator xgboost's best error=0.0260,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:41] {2311} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:42] {2505} INFO -  at 5.8s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:42] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:42] {2505} INFO -  at 5.9s,\testimator xgboost's best error=0.0260,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:42] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:42] {2505} INFO -  at 6.0s,\testimator xgboost's best error=0.0260,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:42] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:42] {2505} INFO -  at 6.2s,\testimator xgboost's best error=0.0119,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:42] {2311} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:42] {2505} INFO -  at 6.4s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:42] {2311} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:43] {2505} INFO -  at 6.7s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:43] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:43] {2505} INFO -  at 6.9s,\testimator xgboost's best error=0.0119,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:43] {2311} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:44] {2505} INFO -  at 8.0s,\testimator extra_tree's best error=0.0128,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:44] {2311} INFO - iteration 26, current learner rf\n",
            "[flaml.automl: 12-13 05:15:45] {2505} INFO -  at 9.2s,\testimator rf's best error=0.0126,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:45] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:45] {2505} INFO -  at 9.3s,\testimator xgboost's best error=0.0119,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:45] {2311} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:46] {2505} INFO -  at 10.5s,\testimator extra_tree's best error=0.0128,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:46] {2311} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:48] {2505} INFO -  at 11.9s,\testimator extra_tree's best error=0.0063,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:48] {2311} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:48] {2505} INFO -  at 12.2s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:48] {2311} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:49] {2505} INFO -  at 12.9s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:49] {2311} INFO - iteration 32, current learner rf\n",
            "[flaml.automl: 12-13 05:15:50] {2505} INFO -  at 14.4s,\testimator rf's best error=0.0047,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:50] {2311} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:52] {2505} INFO -  at 15.6s,\testimator extra_tree's best error=0.0051,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:52] {2311} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:52] {2505} INFO -  at 15.8s,\testimator lgbm's best error=0.0044,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:52] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:52] {2505} INFO -  at 16.0s,\testimator xgboost's best error=0.0080,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:52] {2311} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:53] {2505} INFO -  at 17.5s,\testimator extra_tree's best error=0.0051,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:53] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:54] {2505} INFO -  at 17.6s,\testimator xgboost's best error=0.0080,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:54] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:54] {2505} INFO -  at 17.8s,\testimator xgboost's best error=0.0080,\tbest estimator lgbm's best error=0.0044\n",
            "[flaml.automl: 12-13 05:15:54] {2311} INFO - iteration 39, current learner rf\n",
            "[flaml.automl: 12-13 05:15:55] {2505} INFO -  at 19.0s,\testimator rf's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:55] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:55] {2505} INFO -  at 19.3s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:55] {2311} INFO - iteration 41, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:55] {2505} INFO -  at 19.4s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:55] {2311} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 12-13 05:15:56] {2505} INFO -  at 20.1s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:56] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:56] {2505} INFO -  at 20.3s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:56] {2311} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:15:58] {2505} INFO -  at 21.8s,\testimator extra_tree's best error=0.0046,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:58] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:58] {2505} INFO -  at 21.9s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:58] {2311} INFO - iteration 46, current learner rf\n",
            "[flaml.automl: 12-13 05:15:59] {2505} INFO -  at 23.1s,\testimator rf's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:59] {2311} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-13 05:15:59] {2505} INFO -  at 23.4s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:15:59] {2311} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:00] {2505} INFO -  at 23.8s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:00] {2311} INFO - iteration 49, current learner rf\n",
            "[flaml.automl: 12-13 05:16:01] {2505} INFO -  at 25.0s,\testimator rf's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:01] {2311} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:16:02] {2505} INFO -  at 26.3s,\testimator extra_tree's best error=0.0046,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:02] {2311} INFO - iteration 51, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:03] {2505} INFO -  at 26.6s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:03] {2311} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:04] {2505} INFO -  at 27.8s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:04] {2311} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:04] {2505} INFO -  at 28.5s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:04] {2311} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:05] {2505} INFO -  at 29.1s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:05] {2311} INFO - iteration 55, current learner xgboost\n",
            "[flaml.automl: 12-13 05:16:05] {2505} INFO -  at 29.2s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:05] {2311} INFO - iteration 56, current learner rf\n",
            "[flaml.automl: 12-13 05:16:07] {2505} INFO -  at 30.9s,\testimator rf's best error=0.0042,\tbest estimator rf's best error=0.0042\n",
            "[flaml.automl: 12-13 05:16:07] {2311} INFO - iteration 57, current learner rf\n",
            "[flaml.automl: 12-13 05:16:09] {2505} INFO -  at 32.7s,\testimator rf's best error=0.0041,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:09] {2311} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 12-13 05:16:09] {2505} INFO -  at 32.8s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:09] {2311} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:09] {2505} INFO -  at 33.4s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:09] {2311} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-13 05:16:09] {2505} INFO -  at 33.5s,\testimator xgboost's best error=0.0080,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:09] {2311} INFO - iteration 61, current learner rf\n",
            "[flaml.automl: 12-13 05:16:11] {2505} INFO -  at 35.0s,\testimator rf's best error=0.0041,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:11] {2311} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-13 05:16:11] {2505} INFO -  at 35.4s,\testimator xgboost's best error=0.0077,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:11] {2311} INFO - iteration 63, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:12] {2505} INFO -  at 35.6s,\testimator xgb_limitdepth's best error=0.0843,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:12] {2311} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:12] {2505} INFO -  at 35.8s,\testimator xgb_limitdepth's best error=0.0843,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:12] {2311} INFO - iteration 65, current learner rf\n",
            "[flaml.automl: 12-13 05:16:13] {2505} INFO -  at 37.5s,\testimator rf's best error=0.0041,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:13] {2311} INFO - iteration 66, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:14] {2505} INFO -  at 37.8s,\testimator xgb_limitdepth's best error=0.0088,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:14] {2311} INFO - iteration 67, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:14] {2505} INFO -  at 38.0s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:14] {2311} INFO - iteration 68, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:14] {2505} INFO -  at 38.2s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:14] {2311} INFO - iteration 69, current learner lgbm\n",
            "[flaml.automl: 12-13 05:16:15] {2505} INFO -  at 39.0s,\testimator lgbm's best error=0.0042,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:15] {2311} INFO - iteration 70, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:15] {2505} INFO -  at 39.1s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:15] {2311} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:15] {2505} INFO -  at 39.6s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:15] {2311} INFO - iteration 72, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:16:17] {2505} INFO -  at 40.8s,\testimator extra_tree's best error=0.0043,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:17] {2311} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:17] {2505} INFO -  at 41.1s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:17] {2311} INFO - iteration 74, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:16:19] {2505} INFO -  at 42.8s,\testimator extra_tree's best error=0.0043,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:19] {2311} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:19] {2505} INFO -  at 43.0s,\testimator xgb_limitdepth's best error=0.0072,\tbest estimator rf's best error=0.0041\n",
            "[flaml.automl: 12-13 05:16:19] {2311} INFO - iteration 76, current learner rf\n",
            "[flaml.automl: 12-13 05:16:21] {2505} INFO -  at 44.8s,\testimator rf's best error=0.0040,\tbest estimator rf's best error=0.0040\n",
            "[flaml.automl: 12-13 05:16:21] {2311} INFO - iteration 77, current learner rf\n",
            "[flaml.automl: 12-13 05:16:22] {2505} INFO -  at 46.1s,\testimator rf's best error=0.0040,\tbest estimator rf's best error=0.0040\n",
            "[flaml.automl: 12-13 05:16:22] {2311} INFO - iteration 78, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:22] {2505} INFO -  at 46.4s,\testimator xgb_limitdepth's best error=0.0066,\tbest estimator rf's best error=0.0040\n",
            "[flaml.automl: 12-13 05:16:22] {2311} INFO - iteration 79, current learner rf\n",
            "[flaml.automl: 12-13 05:16:26] {2505} INFO -  at 49.9s,\testimator rf's best error=0.0039,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:26] {2311} INFO - iteration 80, current learner rf\n",
            "[flaml.automl: 12-13 05:16:27] {2505} INFO -  at 51.2s,\testimator rf's best error=0.0039,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:27] {2311} INFO - iteration 81, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:16:27] {2505} INFO -  at 51.5s,\testimator xgb_limitdepth's best error=0.0066,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:27] {2311} INFO - iteration 82, current learner rf\n",
            "[flaml.automl: 12-13 05:16:33] {2505} INFO -  at 57.6s,\testimator rf's best error=0.0039,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:33] {2311} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:16:35] {2505} INFO -  at 58.7s,\testimator extra_tree's best error=0.0043,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:35] {2311} INFO - iteration 84, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:16:36] {2505} INFO -  at 59.8s,\testimator extra_tree's best error=0.0043,\tbest estimator rf's best error=0.0039\n",
            "[flaml.automl: 12-13 05:16:37] {2717} INFO - retrain rf for 1.5s\n",
            "[flaml.automl: 12-13 05:16:37] {2722} INFO - retrained model: RandomForestRegressor(max_features=0.6347607006852164, max_leaf_nodes=166,\n",
            "                      n_estimators=109, n_jobs=-1)\n",
            "[flaml.automl: 12-13 05:16:37] {2100} INFO - fit succeeded\n",
            "[flaml.automl: 12-13 05:16:37] {2102} INFO - Time taken to find the best model: 57.55595588684082\n",
            "[flaml.automl: 12-13 05:16:37] {2116} WARNING - Time taken to find the best model is 96% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50761e38-2570-40f3-bdc0-cc5d66bd0903",
        "id": "bUIrv_D8YMFA"
      },
      "source": [
        "#paste retrained model\n",
        "sugg_reg_low_param = RandomForestRegressor(max_features=0.6347607006852164, max_leaf_nodes=166,\n",
        "                      n_estimators=109, n_jobs=-1)\n",
        "#paste finished\n",
        "sugg_reg_low_param.fit(X_train,y_train)\n",
        "y_pred_l=sugg_reg_low_param.predict(last_row)\n",
        "y_pred_l"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.12903057])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSflbgeHS22R"
      },
      "source": [
        "#for low pred \n",
        "y_pred = sugg_reg_low_param.predict(X_test)\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAlEpAY7S22R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec44c686-82d6-46b3-dae5-659c168b7b06"
      },
      "source": [
        "#for low pred regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.002857922938228507\n",
            "MSE: 1.5177321694140943e-05\n",
            "RMSE: 0.003895808220913979\n",
            "MAPE: 6.20847915428511\n",
            "MedAE 0.002223197048358383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNQOZ0oNIwHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4a4223-d2ac-4fc6-eb58-07a493593b7b"
      },
      "source": [
        "#for close prediction\n",
        "#select rows to use for x,y\n",
        "x_c = df_m_5.iloc[:,np.r_[2:36]].values\n",
        "print(x_c)\n",
        "y_c = df_m_5.iloc[:,[38]].values\n",
        "print(y_c) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.38868 1.39057 1.38632 ... 1.37729 1.37047 1.37513]\n",
            " [1.38573 1.38627 1.3808  ... 1.38085 1.37215 1.37735]\n",
            " [1.38185 1.38332 1.37899 ... 1.38152 1.3769  1.37932]\n",
            " ...\n",
            " [1.1265  1.13547 1.12627 ... 1.12551 1.11859 1.12   ]\n",
            " [1.13422 1.13452 1.12782 ... 1.12295 1.11959 1.12062]\n",
            " [1.12913 1.13239 1.1265  ... 1.13295 1.12051 1.13177]]\n",
            "[[1.38181]\n",
            " [1.38133]\n",
            " [1.3816 ]\n",
            " ...\n",
            " [1.12924]\n",
            " [1.13165]\n",
            " [1.1296 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEJIyPqMViu4"
      },
      "source": [
        "#for close prediction\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_c, y_c, test_size = 0.30)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcac9a2-32de-40a1-a40b-e64dc52d85b1",
        "id": "PdLGMtbGb8ZI"
      },
      "source": [
        "automl_reg = AutoML()\n",
        "automl_reg.fit(X_train, y_train, estimator_list=\"auto\", task=\"regression\", time_budget=None, eval_method=\"auto\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 12-13 05:17:21] {1943} INFO - task = regression\n",
            "[flaml.automl: 12-13 05:17:21] {1945} INFO - Data split method: uniform\n",
            "[flaml.automl: 12-13 05:17:21] {1949} INFO - Evaluation method: cv\n",
            "[flaml.automl: 12-13 05:17:21] {2019} INFO - Minimizing error metric: 1-r2\n",
            "[flaml.automl: 12-13 05:17:21] {2071} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2425} INFO - Estimated sufficient time budget=760s. Estimated necessary time budget=5s.\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.1s,\testimator lgbm's best error=0.4849,\tbest estimator lgbm's best error=0.4849\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.2s,\testimator lgbm's best error=0.4849,\tbest estimator lgbm's best error=0.4849\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.2s,\testimator lgbm's best error=0.1327,\tbest estimator lgbm's best error=0.1327\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.3s,\testimator xgboost's best error=41.0321,\tbest estimator lgbm's best error=0.1327\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.4s,\testimator lgbm's best error=0.0170,\tbest estimator lgbm's best error=0.0170\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.5s,\testimator lgbm's best error=0.0170,\tbest estimator lgbm's best error=0.0170\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:21] {2505} INFO -  at 0.6s,\testimator lgbm's best error=0.0130,\tbest estimator lgbm's best error=0.0130\n",
            "[flaml.automl: 12-13 05:17:21] {2311} INFO - iteration 7, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:23] {2505} INFO -  at 1.9s,\testimator extra_tree's best error=0.0809,\tbest estimator lgbm's best error=0.0130\n",
            "[flaml.automl: 12-13 05:17:23] {2311} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:23] {2505} INFO -  at 2.0s,\testimator lgbm's best error=0.0130,\tbest estimator lgbm's best error=0.0130\n",
            "[flaml.automl: 12-13 05:17:23] {2311} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:23] {2505} INFO -  at 2.0s,\testimator lgbm's best error=0.0130,\tbest estimator lgbm's best error=0.0130\n",
            "[flaml.automl: 12-13 05:17:23] {2311} INFO - iteration 10, current learner rf\n",
            "[flaml.automl: 12-13 05:17:24] {2505} INFO -  at 3.3s,\testimator rf's best error=0.0565,\tbest estimator lgbm's best error=0.0130\n",
            "[flaml.automl: 12-13 05:17:24] {2311} INFO - iteration 11, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:24] {2505} INFO -  at 3.4s,\testimator lgbm's best error=0.0111,\tbest estimator lgbm's best error=0.0111\n",
            "[flaml.automl: 12-13 05:17:24] {2311} INFO - iteration 12, current learner rf\n",
            "[flaml.automl: 12-13 05:17:25] {2505} INFO -  at 4.6s,\testimator rf's best error=0.0139,\tbest estimator lgbm's best error=0.0111\n",
            "[flaml.automl: 12-13 05:17:25] {2311} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:25] {2505} INFO -  at 4.6s,\testimator xgboost's best error=41.0321,\tbest estimator lgbm's best error=0.0111\n",
            "[flaml.automl: 12-13 05:17:25] {2311} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:26] {2505} INFO -  at 4.7s,\testimator lgbm's best error=0.0111,\tbest estimator lgbm's best error=0.0111\n",
            "[flaml.automl: 12-13 05:17:26] {2311} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:26] {2505} INFO -  at 4.9s,\testimator xgboost's best error=8.6859,\tbest estimator lgbm's best error=0.0111\n",
            "[flaml.automl: 12-13 05:17:26] {2311} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:26] {2505} INFO -  at 5.2s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:26] {2311} INFO - iteration 17, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:26] {2505} INFO -  at 5.3s,\testimator xgboost's best error=0.0285,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:26] {2311} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:27] {2505} INFO -  at 5.9s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:27] {2311} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:27] {2505} INFO -  at 6.0s,\testimator xgboost's best error=0.0285,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:27] {2311} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:27] {2505} INFO -  at 6.1s,\testimator xgboost's best error=0.0285,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:27] {2311} INFO - iteration 21, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:27] {2505} INFO -  at 6.2s,\testimator xgboost's best error=0.0156,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:27] {2311} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:27] {2505} INFO -  at 6.4s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:27] {2311} INFO - iteration 23, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:28] {2505} INFO -  at 6.7s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:28] {2311} INFO - iteration 24, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:28] {2505} INFO -  at 7.0s,\testimator xgboost's best error=0.0156,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:28] {2311} INFO - iteration 25, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:29] {2505} INFO -  at 8.2s,\testimator extra_tree's best error=0.0170,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:29] {2311} INFO - iteration 26, current learner rf\n",
            "[flaml.automl: 12-13 05:17:30] {2505} INFO -  at 9.3s,\testimator rf's best error=0.0139,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:30] {2311} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:30] {2505} INFO -  at 9.5s,\testimator xgboost's best error=0.0156,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:30] {2311} INFO - iteration 28, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:31] {2505} INFO -  at 10.6s,\testimator extra_tree's best error=0.0170,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:31] {2311} INFO - iteration 29, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:33] {2505} INFO -  at 11.9s,\testimator extra_tree's best error=0.0102,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:33] {2311} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:33] {2505} INFO -  at 12.2s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:33] {2311} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:34] {2505} INFO -  at 12.8s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:34] {2311} INFO - iteration 32, current learner rf\n",
            "[flaml.automl: 12-13 05:17:35] {2505} INFO -  at 14.1s,\testimator rf's best error=0.0085,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:35] {2311} INFO - iteration 33, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:36] {2505} INFO -  at 15.5s,\testimator extra_tree's best error=0.0085,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:36] {2311} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:37] {2505} INFO -  at 15.7s,\testimator lgbm's best error=0.0080,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:37] {2311} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:37] {2505} INFO -  at 15.9s,\testimator xgboost's best error=0.0116,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:37] {2311} INFO - iteration 36, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:38] {2505} INFO -  at 17.2s,\testimator extra_tree's best error=0.0085,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:38] {2311} INFO - iteration 37, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:38] {2505} INFO -  at 17.3s,\testimator xgboost's best error=0.0116,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:38] {2311} INFO - iteration 38, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:38] {2505} INFO -  at 17.5s,\testimator xgboost's best error=0.0116,\tbest estimator lgbm's best error=0.0080\n",
            "[flaml.automl: 12-13 05:17:38] {2311} INFO - iteration 39, current learner rf\n",
            "[flaml.automl: 12-13 05:17:40] {2505} INFO -  at 18.9s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:40] {2311} INFO - iteration 40, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:40] {2505} INFO -  at 19.2s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:40] {2311} INFO - iteration 41, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:41] {2505} INFO -  at 20.4s,\testimator extra_tree's best error=0.0085,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:41] {2311} INFO - iteration 42, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:42] {2505} INFO -  at 21.1s,\testimator lgbm's best error=0.0080,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:42] {2311} INFO - iteration 43, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:42] {2505} INFO -  at 21.2s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:42] {2311} INFO - iteration 44, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:43] {2505} INFO -  at 22.5s,\testimator extra_tree's best error=0.0085,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:43] {2311} INFO - iteration 45, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:44] {2505} INFO -  at 22.7s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:44] {2311} INFO - iteration 46, current learner rf\n",
            "[flaml.automl: 12-13 05:17:45] {2505} INFO -  at 24.2s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:45] {2311} INFO - iteration 47, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:45] {2505} INFO -  at 24.3s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:45] {2311} INFO - iteration 48, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:45] {2505} INFO -  at 24.5s,\testimator lgbm's best error=0.0080,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:45] {2311} INFO - iteration 49, current learner rf\n",
            "[flaml.automl: 12-13 05:17:47] {2505} INFO -  at 25.9s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:47] {2311} INFO - iteration 50, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:17:48] {2505} INFO -  at 27.2s,\testimator extra_tree's best error=0.0081,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:48] {2311} INFO - iteration 51, current learner rf\n",
            "[flaml.automl: 12-13 05:17:49] {2505} INFO -  at 28.5s,\testimator rf's best error=0.0079,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:49] {2311} INFO - iteration 52, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:50] {2505} INFO -  at 28.7s,\testimator lgbm's best error=0.0080,\tbest estimator rf's best error=0.0079\n",
            "[flaml.automl: 12-13 05:17:50] {2311} INFO - iteration 53, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:50] {2505} INFO -  at 29.2s,\testimator lgbm's best error=0.0078,\tbest estimator lgbm's best error=0.0078\n",
            "[flaml.automl: 12-13 05:17:50] {2311} INFO - iteration 54, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:51] {2505} INFO -  at 29.9s,\testimator lgbm's best error=0.0077,\tbest estimator lgbm's best error=0.0077\n",
            "[flaml.automl: 12-13 05:17:51] {2311} INFO - iteration 55, current learner rf\n",
            "[flaml.automl: 12-13 05:17:52] {2505} INFO -  at 31.7s,\testimator rf's best error=0.0076,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:52] {2311} INFO - iteration 56, current learner rf\n",
            "[flaml.automl: 12-13 05:17:54] {2505} INFO -  at 32.9s,\testimator rf's best error=0.0076,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:54] {2311} INFO - iteration 57, current learner rf\n",
            "[flaml.automl: 12-13 05:17:55] {2505} INFO -  at 34.2s,\testimator rf's best error=0.0076,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:55] {2311} INFO - iteration 58, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:55] {2505} INFO -  at 34.5s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:55] {2311} INFO - iteration 59, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:56] {2505} INFO -  at 34.9s,\testimator lgbm's best error=0.0077,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:56] {2311} INFO - iteration 60, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:56] {2505} INFO -  at 35.0s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:56] {2311} INFO - iteration 61, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:56] {2505} INFO -  at 35.5s,\testimator lgbm's best error=0.0077,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:56] {2311} INFO - iteration 62, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:56] {2505} INFO -  at 35.6s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:56] {2311} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 12-13 05:17:57] {2505} INFO -  at 35.8s,\testimator xgboost's best error=0.0116,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:57] {2311} INFO - iteration 64, current learner lgbm\n",
            "[flaml.automl: 12-13 05:17:57] {2505} INFO -  at 36.3s,\testimator lgbm's best error=0.0077,\tbest estimator rf's best error=0.0076\n",
            "[flaml.automl: 12-13 05:17:57] {2311} INFO - iteration 65, current learner rf\n",
            "[flaml.automl: 12-13 05:17:59] {2505} INFO -  at 38.3s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:17:59] {2311} INFO - iteration 66, current learner xgboost\n",
            "[flaml.automl: 12-13 05:18:00] {2505} INFO -  at 38.7s,\testimator xgboost's best error=0.0107,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:00] {2311} INFO - iteration 67, current learner rf\n",
            "[flaml.automl: 12-13 05:18:01] {2505} INFO -  at 40.0s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:01] {2311} INFO - iteration 68, current learner lgbm\n",
            "[flaml.automl: 12-13 05:18:02] {2505} INFO -  at 41.0s,\testimator lgbm's best error=0.0077,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:02] {2311} INFO - iteration 69, current learner rf\n",
            "[flaml.automl: 12-13 05:18:04] {2505} INFO -  at 43.3s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:04] {2311} INFO - iteration 70, current learner rf\n",
            "[flaml.automl: 12-13 05:18:06] {2505} INFO -  at 44.8s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:06] {2311} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:06] {2505} INFO -  at 45.1s,\testimator xgb_limitdepth's best error=0.0902,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:06] {2311} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:06] {2505} INFO -  at 45.2s,\testimator xgb_limitdepth's best error=0.0902,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:06] {2311} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:06] {2505} INFO -  at 45.5s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:06] {2311} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:07] {2505} INFO -  at 45.8s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:07] {2311} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:07] {2505} INFO -  at 46.0s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:07] {2311} INFO - iteration 76, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:18:08] {2505} INFO -  at 47.2s,\testimator extra_tree's best error=0.0081,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:08] {2311} INFO - iteration 77, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:08] {2505} INFO -  at 47.4s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:08] {2311} INFO - iteration 78, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:09] {2505} INFO -  at 47.9s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:09] {2311} INFO - iteration 79, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:09] {2505} INFO -  at 48.2s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:09] {2311} INFO - iteration 80, current learner rf\n",
            "[flaml.automl: 12-13 05:18:12] {2505} INFO -  at 51.1s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:12] {2311} INFO - iteration 81, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:12] {2505} INFO -  at 51.3s,\testimator xgb_limitdepth's best error=0.0126,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:12] {2311} INFO - iteration 82, current learner xgb_limitdepth\n",
            "[flaml.automl: 12-13 05:18:12] {2505} INFO -  at 51.6s,\testimator xgb_limitdepth's best error=0.0122,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:12] {2311} INFO - iteration 83, current learner xgboost\n",
            "[flaml.automl: 12-13 05:18:13] {2505} INFO -  at 51.9s,\testimator xgboost's best error=0.0107,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:13] {2311} INFO - iteration 84, current learner xgboost\n",
            "[flaml.automl: 12-13 05:18:13] {2505} INFO -  at 52.0s,\testimator xgboost's best error=0.0107,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:13] {2311} INFO - iteration 85, current learner extra_tree\n",
            "[flaml.automl: 12-13 05:18:14] {2505} INFO -  at 53.5s,\testimator extra_tree's best error=0.0081,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:14] {2311} INFO - iteration 86, current learner rf\n",
            "[flaml.automl: 12-13 05:18:16] {2505} INFO -  at 55.3s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:16] {2311} INFO - iteration 87, current learner xgboost\n",
            "[flaml.automl: 12-13 05:18:16] {2505} INFO -  at 55.4s,\testimator xgboost's best error=0.0107,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:16] {2311} INFO - iteration 88, current learner rf\n",
            "[flaml.automl: 12-13 05:18:17] {2505} INFO -  at 56.6s,\testimator rf's best error=0.0075,\tbest estimator rf's best error=0.0075\n",
            "[flaml.automl: 12-13 05:18:17] {2311} INFO - iteration 89, current learner rf\n",
            "[flaml.automl: 12-13 05:18:22] {2505} INFO -  at 60.8s,\testimator rf's best error=0.0074,\tbest estimator rf's best error=0.0074\n",
            "[flaml.automl: 12-13 05:18:23] {2717} INFO - retrain rf for 1.1s\n",
            "[flaml.automl: 12-13 05:18:23] {2722} INFO - retrained model: RandomForestRegressor(max_features=0.5520984120275062, max_leaf_nodes=158,\n",
            "                      n_estimators=103, n_jobs=-1)\n",
            "[flaml.automl: 12-13 05:18:23] {2100} INFO - fit succeeded\n",
            "[flaml.automl: 12-13 05:18:23] {2102} INFO - Time taken to find the best model: 60.82581973075867\n",
            "[flaml.automl: 12-13 05:18:23] {2116} WARNING - Time taken to find the best model is 101% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06014e9c-6dcc-4da4-c4e0-918193dc2e40",
        "id": "VZJwJ49LcI53"
      },
      "source": [
        "#paste retrained model\n",
        "sugg_reg_close_param = RandomForestRegressor(max_features=0.5520984120275062, max_leaf_nodes=158,\n",
        "                      n_estimators=103, n_jobs=-1)\n",
        "#paste finished\n",
        "sugg_reg_close_param.fit(X_train,y_train)\n",
        "y_pred_c=sugg_reg_close_param.predict(last_row)\n",
        "y_pred_c"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.13085623])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviE4TesViu5"
      },
      "source": [
        "#for close prediction\n",
        "y_pred = sugg_reg_close_param.predict(X_test)\n",
        "mape = mean_absolute_percentage_error(y_test,y_pred)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N5zeqU0Viu5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c75892d7-1bea-4551-9e05-42e80097957a"
      },
      "source": [
        "#for close regression score\n",
        "from sklearn import metrics \n",
        "print('MAE:', metrics.mean_absolute_error(y_test,y_pred))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
        "print('MAPE:', mape)\n",
        "print('MedAE', metrics.median_absolute_error(y_test,y_pred)) \n",
        "#print('MdAPE', metrics)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.004513143399275847\n",
            "MSE: 3.631064554320328e-05\n",
            "RMSE: 0.0060258315229687\n",
            "MAPE: 6.373627615870056\n",
            "MedAE 0.0034117639725095295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6tqvMO4EBCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ad285c-141b-45ff-9dea-0bb302dc9801"
      },
      "source": [
        "print('Today the predictions are:')\n",
        "print('high', y_pred_h)\n",
        "print('close', y_pred_c)\n",
        "print('low', y_pred_l)\n",
        "print('Best used as polarities.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today the predictions are:\n",
            "high [1.13363275]\n",
            "close [1.13085623]\n",
            "low [1.12903057]\n",
            "Best used as polarities.\n"
          ]
        }
      ]
    }
  ]
}